{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a0741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###' ################################################################################\n",
    "###'\n",
    "###' IMPORT LIBRARIES\n",
    "###'\n",
    "###'\n",
    "\n",
    "### pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import spacy\n",
    "\n",
    "### punctuation, stop words and English language model\n",
    "from string import punctuation\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spellchecker import SpellChecker\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import scattertext as st\n",
    "\n",
    "### textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "### countvectorizer, tfidfvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "### tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "### gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "\n",
    "### PCA\n",
    "import random\n",
    "from adjustText import adjust_text\n",
    "\n",
    "### plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### kMeans and silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "### ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "###time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef95c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\OWNER\\\\TopicModeling'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c7653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Full Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The inhibitory impact of collaboration on the ...</td>\n",
       "      <td>The continued influence effect  of misinformat...</td>\n",
       "      <td>The continued influence effect  of misinformat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RECALL prompting hierarchy improves responsive...</td>\n",
       "      <td>The purpose of the current study was to expand...</td>\n",
       "      <td>The purpose of the current study was to expand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assessing key soft skills in organizational co...</td>\n",
       "      <td>Soft skills, also known as transversal skills,...</td>\n",
       "      <td>Introduction: Soft skills, also known as trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mapping perceived sentiments in university cam...</td>\n",
       "      <td>A sustainable university campus should accommo...</td>\n",
       "      <td>A sustainable university campus should accommo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The impact of job stress on job satisfaction a...</td>\n",
       "      <td>The main objective of this study is to explore...</td>\n",
       "      <td>Objective: The main objective of this study is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  The inhibitory impact of collaboration on the ...   \n",
       "1  RECALL prompting hierarchy improves responsive...   \n",
       "2  Assessing key soft skills in organizational co...   \n",
       "3  Mapping perceived sentiments in university cam...   \n",
       "4  The impact of job stress on job satisfaction a...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  The continued influence effect  of misinformat...   \n",
       "1  The purpose of the current study was to expand...   \n",
       "2  Soft skills, also known as transversal skills,...   \n",
       "3  A sustainable university campus should accommo...   \n",
       "4  The main objective of this study is to explore...   \n",
       "\n",
       "                                           Full Text  \n",
       "0  The continued influence effect  of misinformat...  \n",
       "1  The purpose of the current study was to expand...  \n",
       "2  Introduction: Soft skills, also known as trans...  \n",
       "3  A sustainable university campus should accommo...  \n",
       "4  Objective: The main objective of this study is...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "# ----------\n",
    "\n",
    "df = pd.read_csv(\"articles_data.csv\")\n",
    "df_S = df[['Title','Abstract','Full Text']].dropna()\n",
    "df_S.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af695be8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3391213950.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 41\u001b[1;36m\u001b[0m\n\u001b[1;33m    `\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "###' ################################################################################\n",
    "###'\n",
    "###' Function for Deleteing Punctuations and StopWords\n",
    "###'\n",
    "###'\n",
    "\n",
    "### define fuction\n",
    "def rem_punc_stop(text):\n",
    "    # When text is None\n",
    "    if text is None:\n",
    "        return []\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Define additional stop words\n",
    "    stop_words = STOP_WORDS | {\"abstract\", \"available\", \"student\", \"research\", \"study\", \"impact\", \"effect\",\n",
    "                               \"result\", \"al\", \"et\", \"doi\", \"googlescholar\", \"google\", \"scholar\", \"textgoogle\", \n",
    "                               \"full\", \"crossref\", \"introduction\", \"background\", \"aim\", \"objective\"}\n",
    "\n",
    "    # Define punctuation\n",
    "    punc = set(punctuation)\n",
    "\n",
    "    # Remove punctuation\n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punc])\n",
    "\n",
    "    # Apply NLP processing\n",
    "    doc = nlp(punc_free)\n",
    "\n",
    "    # Tokenize and lemmatize\n",
    "    text_lemma = \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "    # Filter tokens to remove URLs, stop words, and non-alphabetic tokens\n",
    "    filtered_tokens = [word for word in text_lemma.split() if word not in stop_words and word.isalpha()]\n",
    "\n",
    "    # Return filtered tokens for TfidfVectorizer\n",
    "    return filtered_tokens\n",
    "    \n",
    "\n",
    "###' ################################################################################\n",
    "###'\n",
    "###' Apply the Function and Tokenize Text Column\n",
    "###'\n",
    "###'\n",
    "\n",
    "### sample from the whole dataset\n",
    "df_S['Title_tokens'] = df_S['Title'].map(lambda x: rem_punc_stop(x)[\"filtered_tokens\"])\n",
    "df_S['Title_join'] = df_S['Title_tokens'].map(lambda text: ' '.join(text) if isinstance(text, list) else \"\")\n",
    "\n",
    "df_S['Abstract_tokens'] = df_S['Abstract'].map(lambda x: rem_punc_stop(x)[\"filtered_tokens\"])\n",
    "df_S['Abstract_join'] = df_S['Abstract_tokens'].map(lambda text: ' '.join(text) if isinstance(text, list) else \"\")\n",
    "\n",
    "\n",
    "df_S['Full_tokens'] = df_S['Full Text'].map(lambda x: rem_punc_stop(x)[\"filtered_tokens\"])\n",
    "df_S['Full_join'] = df_S['Full_tokens'].map(lambda text: ' '.join(text) if isinstance(text, list) else \"\")\n",
    "\n",
    "\n",
    "###' ################################################################################\n",
    "###'\n",
    "###' Filter Yet Published Papers\n",
    "###'\n",
    "###'\n",
    "\n",
    "df_S['Full_count'] = df_S['Full Text'].dropna().apply(lambda x: len(str(x).split()))\n",
    "df_S = df_S[df_S['Full_count'] >= 2000]\n",
    "\n",
    "df_S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dcf18",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82b74a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3cfb1c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m df_S[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m tf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(tokenizer \u001b[38;5;241m=\u001b[39m rem_punc_stop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiltered_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# specify our function for remove punc and stop words\u001b[39;00m\n\u001b[0;32m      3\u001b[0m                      token_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)       \u001b[38;5;66;03m# specify \"None\" to remove warning. Is this necessary?\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# apply tf-idf vectorizer to our data (X)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m  tf\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "X = df_S['Full Text']\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop[\"filtered_tokens\"],  # specify our function for remove punc and stop words\n",
    "                     token_pattern = None)       # specify \"None\" to remove warning. Is this necessary?\n",
    "\n",
    "# apply tf-idf vectorizer to our data (X)\n",
    "tfidf_matrix =  tf.fit_transform(X)\n",
    "\n",
    "# modify the output to be a dense matrix\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5fb24d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>filtered_tokens</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_reduced_str</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4    \\\n",
       "filtered_tokens     0.707107  0.707107  0.707107  0.707107  0.707107   \n",
       "tokens_reduced_str  0.707107  0.707107  0.707107  0.707107  0.707107   \n",
       "\n",
       "                         5         6         7         8         9    ...  \\\n",
       "filtered_tokens     0.707107  0.707107  0.707107  0.707107  0.707107  ...   \n",
       "tokens_reduced_str  0.707107  0.707107  0.707107  0.707107  0.707107  ...   \n",
       "\n",
       "                         139       140       141       142       143  \\\n",
       "filtered_tokens     0.707107  0.707107  0.707107  0.707107  0.707107   \n",
       "tokens_reduced_str  0.707107  0.707107  0.707107  0.707107  0.707107   \n",
       "\n",
       "                         144       145       146       147       148  \n",
       "filtered_tokens     0.707107  0.707107  0.707107  0.707107  0.707107  \n",
       "tokens_reduced_str  0.707107  0.707107  0.707107  0.707107  0.707107  \n",
       "\n",
       "[2 rows x 149 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(data = tfidf_matrix.toarray(),       # convert to array than to datafram\n",
    "                        columns=tf.get_feature_names_out())\n",
    "# sort by term frequency on the first document\n",
    "tfidf_df.T.nlargest(10,  # transpose the matrix = columns become documents and rows are words\n",
    "                     0)  # on column index 0 to show the largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "149bf83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sum_of_squared_distances = []\n",
    "\n",
    "K = range(1, 10) \n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k,     # number of clusters\n",
    "                init='k-means++', # method for initalization \n",
    "                n_init=10)        # number of times the k-means algorithm is run with different centroid seeds\n",
    "    km = km.fit(tfidf_matrix)     # fit\n",
    "    Sum_of_squared_distances.append(km.inertia_) # pipe inertia calculations into list\n",
    "\n",
    "\n",
    "# plot results\n",
    "# ---------\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.xticks(range(1, max(K) + 1, 1))\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c03d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7bed59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097475a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6711b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77b5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a4c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "###' ################################################################################\n",
    "###'\n",
    "###' Topic Modeling : Latent Dirichlet Allocation (LDA)\n",
    "###'\n",
    "###'\n",
    "\n",
    "\n",
    "### define function\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nlda_{}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b368f5d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m tf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(tokenizer \u001b[38;5;241m=\u001b[39m rem_punc_stop,  \u001b[38;5;66;03m# specify our function for remove punc and stop words\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                      token_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)       \u001b[38;5;66;03m# specify \"None\" to remove warning. Is this necessary?\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# apply tf-idf vectorizer to our data (X)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m  tf\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# modify the output to be a dense matrix\u001b[39;00m\n\u001b[0;32m     14\u001b[0m dense_matrix \u001b[38;5;241m=\u001b[39m tfidf_matrix\u001b[38;5;241m.\u001b[39mtodense()\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2126\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2121\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2122\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2123\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2124\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2125\u001b[0m )\n\u001b[1;32m-> 2126\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1383\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1375\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1376\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1377\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1379\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1380\u001b[0m             )\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1383\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1386\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1270\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1269\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1272\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:112\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[9], line 30\u001b[0m, in \u001b[0;36mrem_punc_stop\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     27\u001b[0m punc_free \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ch \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m punc])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Apply NLP processing\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(punc_free)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Tokenize and lemmatize\u001b[39;00m\n\u001b[0;32m     33\u001b[0m text_lemma \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m ParserStepModel(\n\u001b[0;32m     35\u001b[0m         X,\n\u001b[0;32m     36\u001b[0m         model\u001b[38;5;241m.\u001b[39mlayers,\n\u001b[0;32m     37\u001b[0m         unseen_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munseen_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     38\u001b[0m         train\u001b[38;5;241m=\u001b[39mis_train,\n\u001b[0;32m     39\u001b[0m         has_upper\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[0;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[0;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m layer(Xr\u001b[38;5;241m.\u001b[39mdataXd, is_train)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\concatenate.py:57\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\concatenate.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\hashembed.py:72\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     70\u001b[0m seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     71\u001b[0m keys \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mhash(ids, seed) \u001b[38;5;241m%\u001b[39m nV\n\u001b[1;32m---> 72\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgather_add(vectors, keys)\n\u001b[0;32m     73\u001b[0m drop_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Latent Dirichlet Allocation (LDA)\n",
    "# ---------------------------------------\n",
    "\n",
    "# pre-processing\n",
    "X = df_S['Full Text']\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop,  # specify our function for remove punc and stop words\n",
    "                     token_pattern = None)       # specify \"None\" to remove warning. Is this necessary?\n",
    "\n",
    "# apply tf-idf vectorizer to our data (X)\n",
    "tfidf_matrix =  tf.fit_transform(X)\n",
    "\n",
    "# modify the output to be a dense matrix\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "\n",
    "# intitialize LDA model and \n",
    "# --------\n",
    "# initialize LDA and set model parameters\n",
    "lda = LatentDirichletAllocation(n_components=5, # specify the number of components\n",
    "                                max_iter=20,    # specify the number of iterations \n",
    "                                random_state=0) # set a seed for reproducibility\n",
    "\n",
    "# fit LDA model to our dense matrix\n",
    "lda = lda.fit(np.asarray(dense_matrix))\n",
    "\n",
    "# post-processing\n",
    "# --------\n",
    "# get feature names from our tf-idf vector\n",
    "tf_feature_names = tf.get_feature_names_out()\n",
    "\n",
    "# print top words \n",
    "print_top_words(lda,               # specify model\n",
    "                tf_feature_names,  # specify feature names vector\n",
    "                20)                # specify how many words we want to see\n",
    " \n",
    "\n",
    "# now transform our data using the lda model and create a dataframe\n",
    "topic_dist = lda.transform(tfidf_matrix)\n",
    "topic_dist_df = pd.DataFrame(topic_dist).reset_index(drop = True)\n",
    "\n",
    "# view the corresponding tf-idf dataframe with tf-idf values\n",
    "topic_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Latent Dirichlet Allocation (LDA)\n",
    "# ---------------------------------------\n",
    "\n",
    "# pre-processing\n",
    "X = df_S['Abstract_join']\n",
    "\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop,\n",
    "                     token_pattern = None) \n",
    "\n",
    "tfidf_mx =  tf.fit_transform(X)\n",
    "\n",
    "dense_matrix = tfidf_mx.todense()\n",
    "\n",
    "\n",
    "# initialize LDA and set model parameters\n",
    "lda = LatentDirichletAllocation(n_components=5,\n",
    "                                max_iter=20,  \n",
    "                                random_state=0) \n",
    "\n",
    "# fit LDA model to our dense matrix\n",
    "lda = lda.fit(numpy.asarray(dense_matrix))\n",
    "\n",
    "# post-processing\n",
    "tf_feature_names = tf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc0835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
