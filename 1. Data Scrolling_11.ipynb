{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eac5082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hyemi\\\\Python\\\\TopicModeling'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007a03a",
   "metadata": {},
   "source": [
    "# Frontier in Psychology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712807f3-b4f8-481c-a49d-0279316e9353",
   "metadata": {},
   "source": [
    "# 1.background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdefa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6164f5",
   "metadata": {},
   "source": [
    "##### Bring URL and HTML\n",
    "url = \"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1487146/full\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3bcdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Convert BeautifulSoup object to string\n",
    "html_content = str(soup)\n",
    "\n",
    "##### Search for title pattern\n",
    "pattern = \"<title.*?>.*?</title.*?>\"\n",
    "match_results = re.search(pattern, html_content, re.IGNORECASE)\n",
    "title = match_results.group() if match_results else \"No title found\"\n",
    "title = re.sub(\"<.*?>\", \"\", title)  # Remove HTML tags\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e360e6",
   "metadata": {},
   "source": [
    "##### https://www.frontiersin.org/journals/psychology/articles?publication-date=25%2F10%2F2024-25%2F10%2F2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6af844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles loaded: 398, Retries: 0\n",
      "Articles loaded: 398, Retries: 1\n",
      "Articles loaded: 398, Retries: 2\n",
      "Articles loaded: 398, Retries: 3\n",
      "Articles loaded: 398, Retries: 4\n",
      "Articles loaded: 398, Retries: 5\n",
      "Articles loaded: 398, Retries: 6\n",
      "Articles loaded: 398, Retries: 7\n",
      "Articles loaded: 398, Retries: 8\n"
     ]
    }
   ],
   "source": [
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "# Open the page\n",
    "base_url = \"https://www.frontiersin.org/journals/psychology/articles\"\n",
    "url = base_url + \"?publication-date=01%2F01%2F2011-31%2F12%2F2011\"\n",
    "driver.get(url)\n",
    "\n",
    "# Set page zoom to 25%\n",
    "driver.execute_script(\"document.body.style.zoom='25%'\")\n",
    "\n",
    "# Accept cookies if the banner appears\n",
    "try:\n",
    "    accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"onetrust-accept-btn-handler\"))\n",
    "    )\n",
    "    accept_cookies_button.click()\n",
    "except:\n",
    "    print(\"No cookie banner detected.\")\n",
    "\n",
    "# Wait for the first article to load\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"CardArticle\"))\n",
    ")\n",
    "\n",
    "# Scroll and hover to trigger loading of new articles\n",
    "scroll_increment = 200\n",
    "scroll_pause_time = 1.5\n",
    "max_retries = 8\n",
    "retries = 0\n",
    "prev_article_count = 0\n",
    "\n",
    "# Scroll until all articles are loaded\n",
    "actions = ActionChains(driver)\n",
    "while retries < max_retries:\n",
    "    # Scroll by a small increment\n",
    "    driver.execute_script(\"window.scrollBy(0, arguments[0]);\", scroll_increment)\n",
    "    time.sleep(scroll_pause_time)\n",
    "    \n",
    "    # Hover over the footer to trigger lazy loading\n",
    "    footer = driver.find_element(By.TAG_NAME, \"footer\")\n",
    "    actions.move_to_element(footer).perform()\n",
    "    \n",
    "    # Check current number of articles loaded\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    articles = soup.find_all(\"article\", class_=\"CardArticle\")\n",
    "    current_article_count = len(articles)\n",
    "    \n",
    "    # Update retry count based on loaded articles\n",
    "    if current_article_count > prev_article_count:\n",
    "        prev_article_count = current_article_count\n",
    "        retries = 0  # Reset retries if new articles loaded\n",
    "    else:\n",
    "        retries += 1  # Increment retry count if no new articles load\n",
    "    print(f\"Articles loaded: {current_article_count}, Retries: {retries}\")\n",
    "\n",
    "# Ensure elements are fully loaded\n",
    "time.sleep(3)\n",
    "\n",
    "# Extract article information with error handling\n",
    "data = []\n",
    "for article in articles:\n",
    "    try:\n",
    "        # Find elements with None handling\n",
    "        title_elem = article.find(\"h1\", class_=\"CardArticle__title\")\n",
    "        date_elem = article.find(\"p\", class_=\"CardArticle__date\")\n",
    "        type_elem = article.find(\"p\", class_=\"CardArticle__type\")\n",
    "        link_elem = article.find(\"a\", class_=\"CardArticle__wrapper\")\n",
    "        \n",
    "        # Extract data with None checks\n",
    "        title = title_elem.get_text(strip=True) if title_elem else None\n",
    "        publish_date = date_elem.get_text(strip=True) if date_elem else None\n",
    "        article_type = type_elem.get_text(strip=True) if type_elem else None\n",
    "        link = link_elem[\"href\"] if link_elem else None\n",
    "        \n",
    "        data.append({\n",
    "            \"Title\": title,\n",
    "            \"Type\": article_type,\n",
    "            \"Published Date\": publish_date,\n",
    "            \"Link\": link,\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159e75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and process the data\n",
    "def clean_publication_dates(df):\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Clean date strings and convert to datetime\n",
    "    df['Published Date'] = df['Published Date'].str.replace(\n",
    "        r'(Published on |Accepted on )', '', \n",
    "        regex=True\n",
    "    )\n",
    "    \n",
    "    # Convert to datetime with proper error handling\n",
    "    df['Published Date'] = pd.to_datetime(\n",
    "        df['Published Date'],\n",
    "        dayfirst=True,  # Assuming date format is DD/MM/YYYY\n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Extract year and handle missing values\n",
    "    df['Year'] = df['Published Date'].dt.strftime('%Y')\n",
    "    df['Year'] = df['Year'].fillna('2011')  # Fill missing years with 2014\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_research_articles(df):\n",
    "    # Filter for Original Research articles\n",
    "    research_df = df[df['Type'] == 'Original Research'].copy()\n",
    "    \n",
    "    # Reset index after filtering\n",
    "    research_df = research_df.reset_index(drop=True)\n",
    "    \n",
    "    return research_df\n",
    "\n",
    "# Process the dataframe\n",
    "processed_df = clean_publication_dates(df)\n",
    "\n",
    "# Filter for Original Research articles\n",
    "research_df = filter_research_articles(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7932307c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#link = \"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1487146/full\"\n",
    "#response = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfeac4ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#abstract_meta = soup.find('meta', attrs={'name': 'citation_abstract'})\n",
    "#abstract = abstract_meta['content']\n",
    "#abstract_text = re.search(r'<p>(.*?)</p>', abstract).group(1)\n",
    "#abstract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da64b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections = [\"Data availability statement\", \"Ethics statement\", \"Author contributions\"]\n",
    "#extracted_text = []\n",
    "#found_section = False\n",
    "\n",
    "# Traverse paragraphs until we reach the first target section\n",
    "#for paragraph in soup.find_all(['p', 'h2']):\n",
    "    # If we encounter any target section, stop the extraction\n",
    "#    if paragraph.name == 'h2' and paragraph.text.strip() in sections:\n",
    "#        found_section = True\n",
    "#        break\n",
    "#    elif paragraph.name == 'p':  # Accumulate text in paragraphs\n",
    "#        extracted_text.append(paragraph.text.strip())\n",
    "\n",
    "# Join and print the extracted text\n",
    "#result = \" \".join(extracted_text)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bda5c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#link = \"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1435688/full\"\n",
    "#response = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#paragraphs = soup.find_all('p')\n",
    "#paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2390d8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#abstract_meta = soup.find('meta', attrs={'name': 'citation_abstract'})\n",
    "#abstract = abstract_meta['content']\n",
    "#abstract_text = re.search(r'<p>(.*?)</p>', abstract).group(1)\n",
    "#abstract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1994fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections = [\"Data availability statement\", \"Ethics statement\", \"Author contributions\"]\n",
    "#extracted_text = []\n",
    "#found_section = False\n",
    "\n",
    "# Traverse paragraphs until we reach the first target section\n",
    "#for paragraph in soup.find_all(['p', 'h2']):\n",
    "    # If we encounter any target section, stop the extraction\n",
    "#    if paragraph.name == 'h2' and paragraph.text.strip() in sections:\n",
    "#        found_section = True\n",
    "#        break\n",
    "#    elif paragraph.name == 'p':  # Accumulate text in paragraphs\n",
    "#        extracted_text.append(paragraph.text.strip())\n",
    "\n",
    "# Join and print the extracted text\n",
    "#result = \" \".join(extracted_text)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce65f4a-4f71-466b-8c12-4ea6a19a7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 1/239\n",
      "Processing article 2/239\n",
      "Processing article 3/239\n",
      "Processing article 4/239\n",
      "Processing article 5/239\n",
      "Processing article 6/239\n",
      "Processing article 7/239\n",
      "Processing article 8/239\n",
      "Processing article 9/239\n",
      "Processing article 10/239\n",
      "Processing article 11/239\n",
      "Processing article 12/239\n",
      "Processing article 13/239\n",
      "Processing article 14/239\n",
      "Processing article 15/239\n",
      "Processing article 16/239\n",
      "Processing article 17/239\n",
      "Processing article 18/239\n",
      "Processing article 19/239\n",
      "Processing article 20/239\n",
      "Processing article 21/239\n",
      "Processing article 22/239\n",
      "Processing article 23/239\n",
      "Processing article 24/239\n",
      "Processing article 25/239\n",
      "Processing article 26/239\n",
      "Processing article 27/239\n",
      "Processing article 28/239\n",
      "Processing article 29/239\n",
      "Processing article 30/239\n",
      "Processing article 31/239\n",
      "Processing article 32/239\n",
      "Processing article 33/239\n",
      "Processing article 34/239\n",
      "Processing article 35/239\n",
      "Processing article 36/239\n",
      "Processing article 37/239\n",
      "Processing article 38/239\n",
      "Processing article 39/239\n",
      "Processing article 40/239\n",
      "Processing article 41/239\n",
      "Processing article 42/239\n",
      "Processing article 43/239\n",
      "Processing article 44/239\n",
      "Processing article 45/239\n",
      "Processing article 46/239\n",
      "Processing article 47/239\n",
      "Processing article 48/239\n",
      "Processing article 49/239\n",
      "Processing article 50/239\n",
      "Processing article 51/239\n",
      "Processing article 52/239\n",
      "Processing article 53/239\n",
      "Processing article 54/239\n",
      "Processing article 55/239\n",
      "Processing article 56/239\n",
      "Processing article 57/239\n",
      "Processing article 58/239\n",
      "Processing article 59/239\n",
      "Processing article 60/239\n",
      "Processing article 61/239\n",
      "Processing article 62/239\n",
      "Processing article 63/239\n",
      "Processing article 64/239\n",
      "Processing article 65/239\n",
      "Processing article 66/239\n",
      "Processing article 67/239\n",
      "Processing article 68/239\n",
      "Processing article 69/239\n",
      "Processing article 70/239\n",
      "Processing article 71/239\n",
      "Processing article 72/239\n",
      "Processing article 73/239\n",
      "Processing article 74/239\n",
      "Processing article 75/239\n",
      "Processing article 76/239\n",
      "Processing article 77/239\n",
      "Processing article 78/239\n",
      "Processing article 79/239\n",
      "Processing article 80/239\n",
      "Processing article 81/239\n",
      "Processing article 82/239\n",
      "Processing article 83/239\n",
      "Processing article 84/239\n",
      "Processing article 85/239\n",
      "Processing article 86/239\n",
      "Processing article 87/239\n",
      "Processing article 88/239\n",
      "Processing article 89/239\n",
      "Processing article 90/239\n",
      "Processing article 91/239\n",
      "Processing article 92/239\n",
      "Processing article 93/239\n",
      "Processing article 94/239\n",
      "Processing article 95/239\n",
      "Processing article 96/239\n",
      "Processing article 97/239\n",
      "Processing article 98/239\n",
      "Processing article 99/239\n",
      "Processing article 100/239\n",
      "Processing article 101/239\n",
      "Processing article 102/239\n",
      "Processing article 103/239\n",
      "Processing article 104/239\n",
      "Processing article 105/239\n",
      "Processing article 106/239\n",
      "Processing article 107/239\n",
      "Processing article 108/239\n",
      "Processing article 109/239\n",
      "Processing article 110/239\n",
      "Processing article 111/239\n",
      "Processing article 112/239\n",
      "Processing article 113/239\n",
      "Processing article 114/239\n",
      "Processing article 115/239\n",
      "Processing article 116/239\n",
      "Processing article 117/239\n",
      "Processing article 118/239\n",
      "Processing article 119/239\n",
      "Processing article 120/239\n",
      "Processing article 121/239\n",
      "Processing article 122/239\n",
      "Processing article 123/239\n",
      "Processing article 124/239\n",
      "Processing article 125/239\n",
      "Processing article 126/239\n",
      "Processing article 127/239\n",
      "Processing article 128/239\n",
      "Processing article 129/239\n",
      "Processing article 130/239\n",
      "Processing article 131/239\n",
      "Processing article 132/239\n",
      "Processing article 133/239\n",
      "Processing article 134/239\n",
      "Processing article 135/239\n",
      "Processing article 136/239\n",
      "Processing article 137/239\n",
      "Processing article 138/239\n",
      "Processing article 139/239\n",
      "Processing article 140/239\n",
      "Processing article 141/239\n",
      "Processing article 142/239\n",
      "Processing article 143/239\n",
      "Processing article 144/239\n",
      "Processing article 145/239\n",
      "Processing article 146/239\n",
      "Processing article 147/239\n",
      "Processing article 148/239\n",
      "Processing article 149/239\n",
      "Processing article 150/239\n",
      "Processing article 151/239\n",
      "Processing article 152/239\n",
      "Processing article 153/239\n",
      "Processing article 154/239\n",
      "Processing article 155/239\n",
      "Processing article 156/239\n",
      "Processing article 157/239\n",
      "Processing article 158/239\n",
      "Processing article 159/239\n",
      "Processing article 160/239\n",
      "Processing article 161/239\n",
      "Processing article 162/239\n",
      "Processing article 163/239\n",
      "Processing article 164/239\n",
      "Processing article 165/239\n",
      "Processing article 166/239\n",
      "Processing article 167/239\n",
      "Processing article 168/239\n",
      "Processing article 169/239\n",
      "Processing article 170/239\n",
      "Processing article 171/239\n",
      "Processing article 172/239\n",
      "Processing article 173/239\n",
      "Processing article 174/239\n",
      "Processing article 175/239\n",
      "Processing article 176/239\n",
      "Processing article 177/239\n",
      "Processing article 178/239\n",
      "Processing article 179/239\n",
      "Processing article 180/239\n",
      "Processing article 181/239\n",
      "Processing article 182/239\n",
      "Processing article 183/239\n",
      "Processing article 184/239\n",
      "Processing article 185/239\n",
      "Processing article 186/239\n",
      "Processing article 187/239\n",
      "Processing article 188/239\n",
      "Processing article 189/239\n",
      "Processing article 190/239\n",
      "Processing article 191/239\n",
      "Processing article 192/239\n",
      "Processing article 193/239\n",
      "Processing article 194/239\n",
      "Processing article 195/239\n",
      "Processing article 196/239\n",
      "Processing article 197/239\n",
      "Processing article 198/239\n",
      "Processing article 199/239\n",
      "Processing article 200/239\n",
      "Processing article 201/239\n",
      "Processing article 202/239\n",
      "Processing article 203/239\n",
      "Processing article 204/239\n",
      "Processing article 205/239\n",
      "Processing article 206/239\n",
      "Processing article 207/239\n",
      "Processing article 208/239\n",
      "Processing article 209/239\n",
      "Processing article 210/239\n",
      "Processing article 211/239\n",
      "Processing article 212/239\n",
      "Processing article 213/239\n",
      "Processing article 214/239\n",
      "Processing article 215/239\n",
      "Processing article 216/239\n",
      "Processing article 217/239\n",
      "Processing article 218/239\n",
      "Processing article 219/239\n",
      "Processing article 220/239\n",
      "Processing article 221/239\n",
      "Processing article 222/239\n",
      "Processing article 223/239\n",
      "Processing article 224/239\n",
      "Processing article 225/239\n",
      "Processing article 226/239\n",
      "Processing article 227/239\n",
      "Processing article 228/239\n",
      "Processing article 229/239\n",
      "Processing article 230/239\n",
      "Processing article 231/239\n",
      "Processing article 232/239\n",
      "Processing article 233/239\n",
      "Processing article 234/239\n",
      "Processing article 235/239\n",
      "Processing article 236/239\n",
      "Processing article 237/239\n",
      "Processing article 238/239\n",
      "Processing article 239/239\n",
      "\n",
      "Processing completed!\n",
      "Total articles processed: 239\n",
      "Articles with abstracts: 239\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Link</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;The mechanisms underlying vocal mimicry in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Strong evidence has accumulated over the pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A structural representation of the hand emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Eye-tracking findings suggest people prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A possible functional role of finger repres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Jakobson (&lt;xref ref-type=\"bibr\" rid=\"B3\"&gt;19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;So far no studies have systematically looke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Linear mixed models (LMMs) provide a still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Theoretical studies of cooperative behavior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Several psychological theories assume that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Title  Year                                               Link  \\\n",
       "0    None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "1    None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "2    None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "3    None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "4    None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "..    ...   ...                                                ...   \n",
       "234  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "235  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "236  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "237  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "238  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "\n",
       "                                              Abstract  \n",
       "0    <p>The mechanisms underlying vocal mimicry in ...  \n",
       "1    <p>Strong evidence has accumulated over the pa...  \n",
       "2    <p>A structural representation of the hand emb...  \n",
       "3    <p>Eye-tracking findings suggest people prefer...  \n",
       "4    <p>A possible functional role of finger repres...  \n",
       "..                                                 ...  \n",
       "234  <p>Jakobson (<xref ref-type=\"bibr\" rid=\"B3\">19...  \n",
       "235  <p>So far no studies have systematically looke...  \n",
       "236  <p>Linear mixed models (LMMs) provide a still ...  \n",
       "237  <p>Theoretical studies of cooperative behavior...  \n",
       "238  <p>Several psychological theories assume that ...  \n",
       "\n",
       "[239 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[403, 408, 429, 500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retries)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    return session\n",
    "\n",
    "def extract_article_details(session, url, retries=3):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = session.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            ## Extract authors\n",
    "            #authors = soup.select('.authors .author-wrapper')\n",
    "            #author_list = [author.get_text(strip=True) for author in authors]\n",
    "            \n",
    "            # Extract abstract\n",
    "            abstract_meta = soup.find('meta', attrs={'name': 'citation_abstract'})\n",
    "            abstract = abstract_meta['content'] if abstract_meta else \"Abstract not available\"\n",
    "            \n",
    "            # Extract title from meta tag (more reliable)\n",
    "            title_meta = soup.find('meta', attrs={'name': 'citation_title'})\n",
    "            title = title_meta['content'] if title_meta else \"Title not available\"\n",
    "            \n",
    "            return {\n",
    "                'Title': title,\n",
    "                #'Authors': '; '.join(author_list) if author_list else \"Authors not available\",\n",
    "                'Abstract': abstract\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == retries - 1:\n",
    "                return {\n",
    "                    'Title': \"Error extracting title\",\n",
    "                    #'Authors': \"Error extracting authors\",\n",
    "                    'Abstract': \"Error extracting abstract\"\n",
    "                }\n",
    "            time.sleep(2 ** attempt)\n",
    "\n",
    "def process_articles(research_df):\n",
    "    session = create_session()\n",
    "    processed_data = []\n",
    "    total_articles = len(research_df)\n",
    "    \n",
    "    for idx, row in research_df.iterrows():\n",
    "        print(f\"Processing article {idx + 1}/{total_articles}\")\n",
    "        \n",
    "        article_data = {\n",
    "            'Title': row['Title'],\n",
    "            'Year': row['Year'],\n",
    "            'Link': row['Link']\n",
    "        }\n",
    "        \n",
    "        if row['Link']:\n",
    "            details = extract_article_details(session, row['Link'])\n",
    "            article_data.update({\n",
    "                #'Authors': details['Authors'],\n",
    "                'Abstract': details['Abstract']\n",
    "            })\n",
    "        else:\n",
    "            article_data.update({\n",
    "                #'Authors': \"Link not available\",\n",
    "                'Abstract': \"Link not available\"\n",
    "            })\n",
    "        \n",
    "        processed_data.append(article_data)\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Process the articles and create final dataset\n",
    "try:\n",
    "    if 'Title' not in research_df.columns or 'Year' not in research_df.columns or 'Link' not in research_df.columns:\n",
    "        raise ValueError(\"Required columns (Title, Year, Link) not found in research_df\")\n",
    "    \n",
    "    final_df = process_articles(research_df)\n",
    "    \n",
    "    print(\"\\nProcessing completed!\")\n",
    "    print(f\"Total articles processed: {len(final_df)}\")\n",
    "    #print(f\"Articles with authors: {final_df['Authors'].notna().sum()}\")\n",
    "    print(f\"Articles with abstracts: {final_df['Abstract'].notna().sum()}\")\n",
    "\n",
    "    # Display DataFrame using IPython display (for Jupyter)\n",
    "    from IPython.display import display\n",
    "    display(final_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during processing: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf499f89-6246-4173-8666-f8ae888f5db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Link</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;The mechanisms underlying vocal mimicry in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Strong evidence has accumulated over the pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A structural representation of the hand emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Eye-tracking findings suggest people prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A possible functional role of finger repres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title  Year                                               Link  \\\n",
       "0  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "1  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "2  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "3  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "4  None  2011  https://www.frontiersin.org/journals/psycholog...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  <p>The mechanisms underlying vocal mimicry in ...  \n",
       "1  <p>Strong evidence has accumulated over the pa...  \n",
       "2  <p>A structural representation of the hand emb...  \n",
       "3  <p>Eye-tracking findings suggest people prefer...  \n",
       "4  <p>A possible functional role of finger repres...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = final_df\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c6f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "        \n",
    "    # Remove HTML tags (including <p> and </p>)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Remove parenthetical content\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    \n",
    "    # Remove numbers, asterisks, and daggers\n",
    "    text = re.sub(r'(\\d+|\\*|†)', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Clean Title and Abstract\n",
    "#result_df['Title'] = result_df['Title'].apply(clean_text)\n",
    "result_df['Abstract'] = result_df['Abstract'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e2902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df['Authors'] = result_df['Authors'].apply(\n",
    "#    lambda x: re.sub(r'(\\d+|\\*|†)', '', x)  # Remove digits, asterisks, and dagger symbols\n",
    "#                .replace(\"??\", \"\")          # Remove any question marks\n",
    "#                .replace(\",,\", \",\")         # Consolidate multiple commas\n",
    "#                .replace(\", ,\", \",\")        # Remove spaced commas\n",
    "#                .replace(\"  \", \" \")         # Remove double spaces\n",
    "#                .replace(\", ,\", \",\")                # Remove any trailing commas or spaces\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7545a69-5c3b-4dd1-a78a-e229a5a31c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year                                           Abstract\n",
      "0    2011  The mechanisms underlying vocal mimicry in ani...\n",
      "1    2011  Strong evidence has accumulated over the past ...\n",
      "2    2011  A structural representation of the hand embedd...\n",
      "3    2011  Eye-tracking findings suggest people prefer to...\n",
      "4    2011  A possible functional role of finger represent...\n",
      "..    ...                                                ...\n",
      "234  2011  Jakobson reports: “The Russian painter Repin w...\n",
      "235  2011  So far no studies have systematically looked i...\n",
      "236  2011  Linear mixed models provide a still underused ...\n",
      "237  2011  Theoretical studies of cooperative behavior ha...\n",
      "238  2010  Several psychological theories assume that the...\n",
      "\n",
      "[239 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df[['Year', 'Abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1da9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"articles_data_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5437233",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5437fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
