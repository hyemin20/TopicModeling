{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76a0741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###' ################################################################################\n",
    "###'\n",
    "###' IMPORT LIBRARIES\n",
    "###'\n",
    "###'\n",
    "\n",
    "### pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import spacy\n",
    "\n",
    "### punctuation, stop words and English language model\n",
    "from string import punctuation\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spellchecker import SpellChecker\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import scattertext as st\n",
    "\n",
    "### textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "### countvectorizer, tfidfvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "### tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "### gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "\n",
    "### PCA\n",
    "import random\n",
    "from adjustText import adjust_text\n",
    "\n",
    "### plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### kMeans and silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "### ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "###time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fef95c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\OWNER\\\\TopicModeling'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c7653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Full Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The inhibitory impact of collaboration on the ...</td>\n",
       "      <td>The continued influence effect  of misinformat...</td>\n",
       "      <td>The continued influence effect  of misinformat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RECALL prompting hierarchy improves responsive...</td>\n",
       "      <td>The purpose of the current study was to expand...</td>\n",
       "      <td>The purpose of the current study was to expand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assessing key soft skills in organizational co...</td>\n",
       "      <td>Soft skills, also known as transversal skills,...</td>\n",
       "      <td>Introduction: Soft skills, also known as trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mapping perceived sentiments in university cam...</td>\n",
       "      <td>A sustainable university campus should accommo...</td>\n",
       "      <td>A sustainable university campus should accommo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The impact of job stress on job satisfaction a...</td>\n",
       "      <td>The main objective of this study is to explore...</td>\n",
       "      <td>Objective: The main objective of this study is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  The inhibitory impact of collaboration on the ...   \n",
       "1  RECALL prompting hierarchy improves responsive...   \n",
       "2  Assessing key soft skills in organizational co...   \n",
       "3  Mapping perceived sentiments in university cam...   \n",
       "4  The impact of job stress on job satisfaction a...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  The continued influence effect  of misinformat...   \n",
       "1  The purpose of the current study was to expand...   \n",
       "2  Soft skills, also known as transversal skills,...   \n",
       "3  A sustainable university campus should accommo...   \n",
       "4  The main objective of this study is to explore...   \n",
       "\n",
       "                                           Full Text  \n",
       "0  The continued influence effect  of misinformat...  \n",
       "1  The purpose of the current study was to expand...  \n",
       "2  Introduction: Soft skills, also known as trans...  \n",
       "3  A sustainable university campus should accommo...  \n",
       "4  Objective: The main objective of this study is...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "# ----------\n",
    "\n",
    "df = pd.read_csv(\"articles_data.csv\")\n",
    "df_S = df[['Title','Abstract','Full Text']].dropna()\n",
    "df_S.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af695be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Title_tokens</th>\n",
       "      <th>Title_join</th>\n",
       "      <th>Abstract_tokens</th>\n",
       "      <th>Abstract_join</th>\n",
       "      <th>Full_tokens</th>\n",
       "      <th>Full_join</th>\n",
       "      <th>Full_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The inhibitory impact of collaboration on the ...</td>\n",
       "      <td>The continued influence effect  of misinformat...</td>\n",
       "      <td>The continued influence effect  of misinformat...</td>\n",
       "      <td>[inhibitory, collaboration, continue, influenc...</td>\n",
       "      <td>inhibitory collaboration continue influence mi...</td>\n",
       "      <td>[continue, influence, misinformation, refer, p...</td>\n",
       "      <td>continue influence misinformation refer persis...</td>\n",
       "      <td>[continue, influence, misinformation, refer, p...</td>\n",
       "      <td>continue influence misinformation refer persis...</td>\n",
       "      <td>6909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RECALL prompting hierarchy improves responsive...</td>\n",
       "      <td>The purpose of the current study was to expand...</td>\n",
       "      <td>The purpose of the current study was to expand...</td>\n",
       "      <td>[recall, prompt, hierarchy, improve, responsiv...</td>\n",
       "      <td>recall prompt hierarchy improve responsiveness...</td>\n",
       "      <td>[purpose, current, expand, previous, recall, d...</td>\n",
       "      <td>purpose current expand previous recall dialogi...</td>\n",
       "      <td>[purpose, current, expand, previous, recall, d...</td>\n",
       "      <td>purpose current expand previous recall dialogi...</td>\n",
       "      <td>6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assessing key soft skills in organizational co...</td>\n",
       "      <td>Soft skills, also known as transversal skills,...</td>\n",
       "      <td>Introduction: Soft skills, also known as trans...</td>\n",
       "      <td>[assess, key, soft, skill, organizational, con...</td>\n",
       "      <td>assess key soft skill organizational context d...</td>\n",
       "      <td>[soft, skill, know, transversal, skill, gain, ...</td>\n",
       "      <td>soft skill know transversal skill gain signifi...</td>\n",
       "      <td>[soft, skill, know, transversal, skill, gain, ...</td>\n",
       "      <td>soft skill know transversal skill gain signifi...</td>\n",
       "      <td>5729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mapping perceived sentiments in university cam...</td>\n",
       "      <td>A sustainable university campus should accommo...</td>\n",
       "      <td>A sustainable university campus should accommo...</td>\n",
       "      <td>[mapping, perceive, sentiment, university, cam...</td>\n",
       "      <td>mapping perceive sentiment university campus v...</td>\n",
       "      <td>[sustainable, university, campus, accommodate,...</td>\n",
       "      <td>sustainable university campus accommodate expe...</td>\n",
       "      <td>[sustainable, university, campus, accommodate,...</td>\n",
       "      <td>sustainable university campus accommodate expe...</td>\n",
       "      <td>6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The impact of job stress on job satisfaction a...</td>\n",
       "      <td>The main objective of this study is to explore...</td>\n",
       "      <td>Objective: The main objective of this study is...</td>\n",
       "      <td>[job, stress, job, satisfaction, turnover, int...</td>\n",
       "      <td>job stress job satisfaction turnover intention...</td>\n",
       "      <td>[main, explore, relationship, job, stress, job...</td>\n",
       "      <td>main explore relationship job stress job satis...</td>\n",
       "      <td>[main, explore, relationship, job, stress, job...</td>\n",
       "      <td>main explore relationship job stress job satis...</td>\n",
       "      <td>6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Gaze communicates both cue direction and agent...</td>\n",
       "      <td>Although it is well established that humans sp...</td>\n",
       "      <td>Introduction: Although it is well established ...</td>\n",
       "      <td>[gaze, communicate, cue, direction, agent, men...</td>\n",
       "      <td>gaze communicate cue direction agent mental state</td>\n",
       "      <td>[establish, human, spontaneously, attend, look...</td>\n",
       "      <td>establish human spontaneously attend look rema...</td>\n",
       "      <td>[establish, human, spontaneously, attend, look...</td>\n",
       "      <td>establish human spontaneously attend look rema...</td>\n",
       "      <td>5553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>The effect of parental and teacher autonomy su...</td>\n",
       "      <td>According to career construction theory, middl...</td>\n",
       "      <td>Introduction: According to career construction...</td>\n",
       "      <td>[parental, teacher, autonomy, support, core, s...</td>\n",
       "      <td>parental teacher autonomy support core selfeva...</td>\n",
       "      <td>[accord, career, construction, theory, middle,...</td>\n",
       "      <td>accord career construction theory middle schoo...</td>\n",
       "      <td>[accord, career, construction, theory, middle,...</td>\n",
       "      <td>accord career construction theory middle schoo...</td>\n",
       "      <td>5595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Internet addiction, social phobia, substance a...</td>\n",
       "      <td>Internet addiction is a mental health issue th...</td>\n",
       "      <td>Aim: Internet addiction is a mental health iss...</td>\n",
       "      <td>[internet, addiction, social, phobia, substanc...</td>\n",
       "      <td>internet addiction social phobia substance abu...</td>\n",
       "      <td>[internet, addiction, mental, health, issue, d...</td>\n",
       "      <td>internet addiction mental health issue detrime...</td>\n",
       "      <td>[internet, addiction, mental, health, issue, d...</td>\n",
       "      <td>internet addiction mental health issue detrime...</td>\n",
       "      <td>3946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Influence of problem-solving ability and perso...</td>\n",
       "      <td>Basketball players are increasingly required n...</td>\n",
       "      <td>Background: Basketball players are increasingl...</td>\n",
       "      <td>[influence, problemsolving, ability, personali...</td>\n",
       "      <td>influence problemsolving ability personality v...</td>\n",
       "      <td>[basketball, player, increasingly, require, re...</td>\n",
       "      <td>basketball player increasingly require read ta...</td>\n",
       "      <td>[basketball, player, increasingly, require, re...</td>\n",
       "      <td>basketball player increasingly require read ta...</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Strategies for becoming a more desirable mate:...</td>\n",
       "      <td>Mate-seekers employ several strategies to beco...</td>\n",
       "      <td>Introduction: Mate-seekers employ several stra...</td>\n",
       "      <td>[strategy, desirable, mate, evidence, lithuania]</td>\n",
       "      <td>strategy desirable mate evidence lithuania</td>\n",
       "      <td>[mateseeker, employ, strategy, attractive, mat...</td>\n",
       "      <td>mateseeker employ strategy attractive mate pre...</td>\n",
       "      <td>[mateseeker, employ, strategy, attractive, mat...</td>\n",
       "      <td>mateseeker employ strategy attractive mate pre...</td>\n",
       "      <td>3306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    The inhibitory impact of collaboration on the ...   \n",
       "1    RECALL prompting hierarchy improves responsive...   \n",
       "2    Assessing key soft skills in organizational co...   \n",
       "3    Mapping perceived sentiments in university cam...   \n",
       "4    The impact of job stress on job satisfaction a...   \n",
       "..                                                 ...   \n",
       "205  Gaze communicates both cue direction and agent...   \n",
       "206  The effect of parental and teacher autonomy su...   \n",
       "207  Internet addiction, social phobia, substance a...   \n",
       "208  Influence of problem-solving ability and perso...   \n",
       "209  Strategies for becoming a more desirable mate:...   \n",
       "\n",
       "                                              Abstract  \\\n",
       "0    The continued influence effect  of misinformat...   \n",
       "1    The purpose of the current study was to expand...   \n",
       "2    Soft skills, also known as transversal skills,...   \n",
       "3    A sustainable university campus should accommo...   \n",
       "4    The main objective of this study is to explore...   \n",
       "..                                                 ...   \n",
       "205  Although it is well established that humans sp...   \n",
       "206  According to career construction theory, middl...   \n",
       "207  Internet addiction is a mental health issue th...   \n",
       "208  Basketball players are increasingly required n...   \n",
       "209  Mate-seekers employ several strategies to beco...   \n",
       "\n",
       "                                             Full Text  \\\n",
       "0    The continued influence effect  of misinformat...   \n",
       "1    The purpose of the current study was to expand...   \n",
       "2    Introduction: Soft skills, also known as trans...   \n",
       "3    A sustainable university campus should accommo...   \n",
       "4    Objective: The main objective of this study is...   \n",
       "..                                                 ...   \n",
       "205  Introduction: Although it is well established ...   \n",
       "206  Introduction: According to career construction...   \n",
       "207  Aim: Internet addiction is a mental health iss...   \n",
       "208  Background: Basketball players are increasingl...   \n",
       "209  Introduction: Mate-seekers employ several stra...   \n",
       "\n",
       "                                          Title_tokens  \\\n",
       "0    [inhibitory, collaboration, continue, influenc...   \n",
       "1    [recall, prompt, hierarchy, improve, responsiv...   \n",
       "2    [assess, key, soft, skill, organizational, con...   \n",
       "3    [mapping, perceive, sentiment, university, cam...   \n",
       "4    [job, stress, job, satisfaction, turnover, int...   \n",
       "..                                                 ...   \n",
       "205  [gaze, communicate, cue, direction, agent, men...   \n",
       "206  [parental, teacher, autonomy, support, core, s...   \n",
       "207  [internet, addiction, social, phobia, substanc...   \n",
       "208  [influence, problemsolving, ability, personali...   \n",
       "209   [strategy, desirable, mate, evidence, lithuania]   \n",
       "\n",
       "                                            Title_join  \\\n",
       "0    inhibitory collaboration continue influence mi...   \n",
       "1    recall prompt hierarchy improve responsiveness...   \n",
       "2    assess key soft skill organizational context d...   \n",
       "3    mapping perceive sentiment university campus v...   \n",
       "4    job stress job satisfaction turnover intention...   \n",
       "..                                                 ...   \n",
       "205  gaze communicate cue direction agent mental state   \n",
       "206  parental teacher autonomy support core selfeva...   \n",
       "207  internet addiction social phobia substance abu...   \n",
       "208  influence problemsolving ability personality v...   \n",
       "209         strategy desirable mate evidence lithuania   \n",
       "\n",
       "                                       Abstract_tokens  \\\n",
       "0    [continue, influence, misinformation, refer, p...   \n",
       "1    [purpose, current, expand, previous, recall, d...   \n",
       "2    [soft, skill, know, transversal, skill, gain, ...   \n",
       "3    [sustainable, university, campus, accommodate,...   \n",
       "4    [main, explore, relationship, job, stress, job...   \n",
       "..                                                 ...   \n",
       "205  [establish, human, spontaneously, attend, look...   \n",
       "206  [accord, career, construction, theory, middle,...   \n",
       "207  [internet, addiction, mental, health, issue, d...   \n",
       "208  [basketball, player, increasingly, require, re...   \n",
       "209  [mateseeker, employ, strategy, attractive, mat...   \n",
       "\n",
       "                                         Abstract_join  \\\n",
       "0    continue influence misinformation refer persis...   \n",
       "1    purpose current expand previous recall dialogi...   \n",
       "2    soft skill know transversal skill gain signifi...   \n",
       "3    sustainable university campus accommodate expe...   \n",
       "4    main explore relationship job stress job satis...   \n",
       "..                                                 ...   \n",
       "205  establish human spontaneously attend look rema...   \n",
       "206  accord career construction theory middle schoo...   \n",
       "207  internet addiction mental health issue detrime...   \n",
       "208  basketball player increasingly require read ta...   \n",
       "209  mateseeker employ strategy attractive mate pre...   \n",
       "\n",
       "                                           Full_tokens  \\\n",
       "0    [continue, influence, misinformation, refer, p...   \n",
       "1    [purpose, current, expand, previous, recall, d...   \n",
       "2    [soft, skill, know, transversal, skill, gain, ...   \n",
       "3    [sustainable, university, campus, accommodate,...   \n",
       "4    [main, explore, relationship, job, stress, job...   \n",
       "..                                                 ...   \n",
       "205  [establish, human, spontaneously, attend, look...   \n",
       "206  [accord, career, construction, theory, middle,...   \n",
       "207  [internet, addiction, mental, health, issue, d...   \n",
       "208  [basketball, player, increasingly, require, re...   \n",
       "209  [mateseeker, employ, strategy, attractive, mat...   \n",
       "\n",
       "                                             Full_join  Full_count  \n",
       "0    continue influence misinformation refer persis...        6909  \n",
       "1    purpose current expand previous recall dialogi...        6970  \n",
       "2    soft skill know transversal skill gain signifi...        5729  \n",
       "3    sustainable university campus accommodate expe...        6180  \n",
       "4    main explore relationship job stress job satis...        6940  \n",
       "..                                                 ...         ...  \n",
       "205  establish human spontaneously attend look rema...        5553  \n",
       "206  accord career construction theory middle schoo...        5595  \n",
       "207  internet addiction mental health issue detrime...        3946  \n",
       "208  basketball player increasingly require read ta...        4575  \n",
       "209  mateseeker employ strategy attractive mate pre...        3306  \n",
       "\n",
       "[149 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "###' ################################################################################\n",
    "###'\n",
    "###' Function for Deleteing Punctuations and StopWords\n",
    "###'\n",
    "###'\n",
    "\n",
    "### define fuction\n",
    "def rem_punc_stop(text):\n",
    "    # When text is None\n",
    "    if text is None:\n",
    "        return []\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Define additional stop words\n",
    "    stop_words = STOP_WORDS | {\"abstract\", \"available\", \"student\", \"research\", \"study\", \"impact\", \"effect\",\n",
    "                               \"result\", \"al\", \"et\", \"doi\", \"googlescholar\", \"google\", \"scholar\", \"textgoogle\", \n",
    "                               \"full\", \"crossref\", \"introduction\", \"background\", \"aim\", \"objective\"}\n",
    "\n",
    "    # Define punctuation\n",
    "    punc = set(punctuation)\n",
    "\n",
    "    # Remove punctuation\n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punc])\n",
    "\n",
    "    # Apply NLP processing\n",
    "    doc = nlp(punc_free)\n",
    "\n",
    "    # Tokenize and lemmatize\n",
    "    text_lemma = \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "    # Filter tokens to remove URLs, stop words, and non-alphabetic tokens\n",
    "    filtered_tokens = [word for word in text_lemma.split() if word not in stop_words and word.isalpha()]\n",
    "\n",
    "    # Return filtered tokens for TfidfVectorizer\n",
    "    return filtered_tokens\n",
    "    \n",
    "\n",
    "###' ################################################################################\n",
    "###'\n",
    "###' Apply the Function and Tokenize Text Column\n",
    "###'\n",
    "###'\n",
    "\n",
    "### sample from the whole dataset\n",
    "df_S['Title_tokens'] = df_S['Title'].map(lambda x: rem_punc_stop(x))\n",
    "df_S['Title_join'] = df_S['Title_tokens'].map(lambda text: ' '.join(text) if isinstance(text, list) else \"\")\n",
    "\n",
    "df_S['Abstract_tokens'] = df_S['Abstract'].map(lambda x: rem_punc_stop(x))\n",
    "df_S['Abstract_join'] = df_S['Abstract_tokens'].map(lambda text: ' '.join(text) if isinstance(text, list) else \"\")\n",
    "\n",
    "\n",
    "df_S['Full_tokens'] = df_S['Full Text'].map(lambda x: rem_punc_stop(x))\n",
    "df_S['Full_join'] = df_S['Full_tokens'].map(lambda text: ' '.join(text) if isinstance(text, list) else \"\")\n",
    "\n",
    "\n",
    "###' ################################################################################\n",
    "###'\n",
    "###' Filter Yet Published Papers\n",
    "###'\n",
    "###'\n",
    "\n",
    "df_S['Full_count'] = df_S['Full Text'].dropna().apply(lambda x: len(str(x).split()))\n",
    "df_S = df_S[df_S['Full_count'] >= 2000]\n",
    "\n",
    "df_S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc23cc",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76fdaf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678],\n",
       "        [0.70710678, 0.70710678]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c468396c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00262167, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.01926746, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_S['Full Text']\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop,  # specify our function for remove punc and stop words\n",
    "                     token_pattern = None)       # specify \"None\" to remove warning. Is this necessary?\n",
    "\n",
    "# apply tf-idf vectorizer to our data (X)\n",
    "tfidf_matrix =  tf.fit_transform(X)\n",
    "\n",
    "# modify the output to be a dense matrix\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ef70203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>collaboration</th>\n",
       "      <td>0.477442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cie</th>\n",
       "      <td>0.359712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ƞ</th>\n",
       "      <td>0.356497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.332166</td>\n",
       "      <td>0.168985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memory</th>\n",
       "      <td>0.227371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>0.191615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turntaking</th>\n",
       "      <td>0.166937</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correction</th>\n",
       "      <td>0.165623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nominal</th>\n",
       "      <td>0.154342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>0.150727</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.147310</td>\n",
       "      <td>0.089752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5    \\\n",
       "collaboration  0.477442  0.000000  0.005630  0.000000  0.000000  0.000000   \n",
       "cie            0.359712  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ƞ              0.356497  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "recall         0.332166  0.168985  0.000000  0.000000  0.000000  0.000000   \n",
       "memory         0.227371  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "free           0.191615  0.000000  0.000000  0.003346  0.000000  0.008195   \n",
       "turntaking     0.166937  0.006602  0.000000  0.000000  0.000000  0.000000   \n",
       "correction     0.165623  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "nominal        0.154342  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "condition      0.150727  0.001897  0.005203  0.005241  0.004772  0.000000   \n",
       "\n",
       "                    6         7         8         9    ...       139  \\\n",
       "collaboration  0.000000  0.016717  0.000000  0.000000  ...  0.000000   \n",
       "cie            0.076688  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "ƞ              0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "recall         0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "memory         0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "free           0.000000  0.000000  0.000000  0.004193  ...  0.000000   \n",
       "turntaking     0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "correction     0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "nominal        0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "condition      0.005185  0.003862  0.013054  0.004378  ...  0.048018   \n",
       "\n",
       "                    140       141       142       143       144  145  \\\n",
       "collaboration  0.000000  0.000000  0.006724  0.000000  0.000000  0.0   \n",
       "cie            0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "ƞ              0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "recall         0.000000  0.000000  0.000000  0.006104  0.000000  0.0   \n",
       "memory         0.000000  0.000000  0.000000  0.004989  0.000000  0.0   \n",
       "free           0.000000  0.000000  0.000000  0.005644  0.000000  0.0   \n",
       "turntaking     0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "correction     0.019027  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "nominal        0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "condition      0.000000  0.003657  0.001553  0.147310  0.089752  0.0   \n",
       "\n",
       "                    146       147       148  \n",
       "collaboration  0.000000  0.000000  0.000000  \n",
       "cie            0.000000  0.000000  0.000000  \n",
       "ƞ              0.000000  0.000000  0.000000  \n",
       "recall         0.005177  0.000000  0.000000  \n",
       "memory         0.000000  0.004474  0.000000  \n",
       "free           0.000000  0.000000  0.000000  \n",
       "turntaking     0.000000  0.000000  0.000000  \n",
       "correction     0.016473  0.000000  0.007659  \n",
       "nominal        0.000000  0.000000  0.000000  \n",
       "condition      0.002499  0.005284  0.000000  \n",
       "\n",
       "[10 rows x 149 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(data = tfidf_matrix.toarray(),       # convert to array than to datafram\n",
    "                        columns=tf.get_feature_names_out())\n",
    "# sort by term frequency on the first document\n",
    "tfidf_df.T.nlargest(10,  # transpose the matrix = columns become documents and rows are words\n",
    "                     0)  # on column index 0 to show the largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9608464f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sum_of_squared_distances = []\n",
    "\n",
    "K = range(2, 10) \n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k,     # number of clusters\n",
    "                init='k-means++', # method for initalization \n",
    "                n_init=10)        # number of times the k-means algorithm is run with different centroid seeds\n",
    "    km = km.fit(tfidf_matrix)     # fit\n",
    "    Sum_of_squared_distances.append(km.inertia_) # pipe inertia calculations into list\n",
    "\n",
    "\n",
    "# plot results\n",
    "# ---------\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.xticks(range(1, max(K) + 1, 1))\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03908beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7dd3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab1f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ca251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2187ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a4c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "###' ################################################################################\n",
    "###'\n",
    "###' Topic Modeling : Latent Dirichlet Allocation (LDA)\n",
    "###'\n",
    "###'\n",
    "\n",
    "\n",
    "### define function\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nlda_{}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b368f5d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m tf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(tokenizer \u001b[38;5;241m=\u001b[39m rem_punc_stop,  \u001b[38;5;66;03m# specify our function for remove punc and stop words\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                      token_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)       \u001b[38;5;66;03m# specify \"None\" to remove warning. Is this necessary?\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# apply tf-idf vectorizer to our data (X)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m  tf\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# modify the output to be a dense matrix\u001b[39;00m\n\u001b[0;32m     14\u001b[0m dense_matrix \u001b[38;5;241m=\u001b[39m tfidf_matrix\u001b[38;5;241m.\u001b[39mtodense()\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2126\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2121\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2122\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2123\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2124\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2125\u001b[0m )\n\u001b[1;32m-> 2126\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1383\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1375\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1376\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1377\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1379\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1380\u001b[0m             )\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1383\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1386\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1270\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1269\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1272\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mD:\\Program\\ANACONDA\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:112\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[9], line 30\u001b[0m, in \u001b[0;36mrem_punc_stop\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     27\u001b[0m punc_free \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ch \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m punc])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Apply NLP processing\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(punc_free)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Tokenize and lemmatize\u001b[39;00m\n\u001b[0;32m     33\u001b[0m text_lemma \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m ParserStepModel(\n\u001b[0;32m     35\u001b[0m         X,\n\u001b[0;32m     36\u001b[0m         model\u001b[38;5;241m.\u001b[39mlayers,\n\u001b[0;32m     37\u001b[0m         unseen_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munseen_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     38\u001b[0m         train\u001b[38;5;241m=\u001b[39mis_train,\n\u001b[0;32m     39\u001b[0m         has_upper\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[0;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[0;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m layer(Xr\u001b[38;5;241m.\u001b[39mdataXd, is_train)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\concatenate.py:57\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\concatenate.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\layers\\hashembed.py:72\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     70\u001b[0m seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     71\u001b[0m keys \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mhash(ids, seed) \u001b[38;5;241m%\u001b[39m nV\n\u001b[1;32m---> 72\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgather_add(vectors, keys)\n\u001b[0;32m     73\u001b[0m drop_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Latent Dirichlet Allocation (LDA)\n",
    "# ---------------------------------------\n",
    "\n",
    "# pre-processing\n",
    "X = df_S['Full Text']\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop,  # specify our function for remove punc and stop words\n",
    "                     token_pattern = None)       # specify \"None\" to remove warning. Is this necessary?\n",
    "\n",
    "# apply tf-idf vectorizer to our data (X)\n",
    "tfidf_matrix =  tf.fit_transform(X)\n",
    "\n",
    "# modify the output to be a dense matrix\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "\n",
    "# intitialize LDA model and \n",
    "# --------\n",
    "# initialize LDA and set model parameters\n",
    "lda = LatentDirichletAllocation(n_components=5, # specify the number of components\n",
    "                                max_iter=20,    # specify the number of iterations \n",
    "                                random_state=0) # set a seed for reproducibility\n",
    "\n",
    "# fit LDA model to our dense matrix\n",
    "lda = lda.fit(np.asarray(dense_matrix))\n",
    "\n",
    "# post-processing\n",
    "# --------\n",
    "# get feature names from our tf-idf vector\n",
    "tf_feature_names = tf.get_feature_names_out()\n",
    "\n",
    "# print top words \n",
    "print_top_words(lda,               # specify model\n",
    "                tf_feature_names,  # specify feature names vector\n",
    "                20)                # specify how many words we want to see\n",
    " \n",
    "\n",
    "# now transform our data using the lda model and create a dataframe\n",
    "topic_dist = lda.transform(tfidf_matrix)\n",
    "topic_dist_df = pd.DataFrame(topic_dist).reset_index(drop = True)\n",
    "\n",
    "# view the corresponding tf-idf dataframe with tf-idf values\n",
    "topic_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Latent Dirichlet Allocation (LDA)\n",
    "# ---------------------------------------\n",
    "\n",
    "# pre-processing\n",
    "X = df_S['Abstract_join']\n",
    "\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop,\n",
    "                     token_pattern = None) \n",
    "\n",
    "tfidf_mx =  tf.fit_transform(X)\n",
    "\n",
    "dense_matrix = tfidf_mx.todense()\n",
    "\n",
    "\n",
    "# initialize LDA and set model parameters\n",
    "lda = LatentDirichletAllocation(n_components=5,\n",
    "                                max_iter=20,  \n",
    "                                random_state=0) \n",
    "\n",
    "# fit LDA model to our dense matrix\n",
    "lda = lda.fit(numpy.asarray(dense_matrix))\n",
    "\n",
    "# post-processing\n",
    "tf_feature_names = tf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc0835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
