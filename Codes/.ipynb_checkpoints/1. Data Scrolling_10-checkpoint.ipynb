{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eac5082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hyemi\\\\Python\\\\TopicModeling'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007a03a",
   "metadata": {},
   "source": [
    "# Frontier in Psychology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712807f3-b4f8-481c-a49d-0279316e9353",
   "metadata": {},
   "source": [
    "# 1.background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdefa19b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6164f5",
   "metadata": {},
   "source": [
    "##### Bring URL and HTML\n",
    "url = \"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1487146/full\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3bcdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Convert BeautifulSoup object to string\n",
    "html_content = str(soup)\n",
    "\n",
    "##### Search for title pattern\n",
    "pattern = \"<title.*?>.*?</title.*?>\"\n",
    "match_results = re.search(pattern, html_content, re.IGNORECASE)\n",
    "title = match_results.group() if match_results else \"No title found\"\n",
    "title = re.sub(\"<.*?>\", \"\", title)  # Remove HTML tags\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e360e6",
   "metadata": {},
   "source": [
    "##### https://www.frontiersin.org/journals/psychology/articles?publication-date=25%2F10%2F2024-25%2F10%2F2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6af844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles loaded: 128, Retries: 0\n",
      "Articles loaded: 128, Retries: 1\n",
      "Articles loaded: 128, Retries: 2\n",
      "Articles loaded: 128, Retries: 3\n",
      "Articles loaded: 128, Retries: 4\n",
      "Articles loaded: 128, Retries: 5\n",
      "Articles loaded: 128, Retries: 6\n",
      "Articles loaded: 128, Retries: 7\n",
      "Articles loaded: 128, Retries: 8\n"
     ]
    }
   ],
   "source": [
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "# Open the page\n",
    "base_url = \"https://www.frontiersin.org/journals/psychology/articles\"\n",
    "url = base_url + \"?publication-date=01%2F01%2F2010-31%2F12%2F2010\"\n",
    "driver.get(url)\n",
    "\n",
    "# Set page zoom to 25%\n",
    "driver.execute_script(\"document.body.style.zoom='25%'\")\n",
    "\n",
    "# Accept cookies if the banner appears\n",
    "try:\n",
    "    accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"onetrust-accept-btn-handler\"))\n",
    "    )\n",
    "    accept_cookies_button.click()\n",
    "except:\n",
    "    print(\"No cookie banner detected.\")\n",
    "\n",
    "# Wait for the first article to load\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"CardArticle\"))\n",
    ")\n",
    "\n",
    "# Scroll and hover to trigger loading of new articles\n",
    "scroll_increment = 200\n",
    "scroll_pause_time = 1.5\n",
    "max_retries = 8\n",
    "retries = 0\n",
    "prev_article_count = 0\n",
    "\n",
    "# Scroll until all articles are loaded\n",
    "actions = ActionChains(driver)\n",
    "while retries < max_retries:\n",
    "    # Scroll by a small increment\n",
    "    driver.execute_script(\"window.scrollBy(0, arguments[0]);\", scroll_increment)\n",
    "    time.sleep(scroll_pause_time)\n",
    "    \n",
    "    # Hover over the footer to trigger lazy loading\n",
    "    footer = driver.find_element(By.TAG_NAME, \"footer\")\n",
    "    actions.move_to_element(footer).perform()\n",
    "    \n",
    "    # Check current number of articles loaded\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    articles = soup.find_all(\"article\", class_=\"CardArticle\")\n",
    "    current_article_count = len(articles)\n",
    "    \n",
    "    # Update retry count based on loaded articles\n",
    "    if current_article_count > prev_article_count:\n",
    "        prev_article_count = current_article_count\n",
    "        retries = 0  # Reset retries if new articles loaded\n",
    "    else:\n",
    "        retries += 1  # Increment retry count if no new articles load\n",
    "    print(f\"Articles loaded: {current_article_count}, Retries: {retries}\")\n",
    "\n",
    "# Ensure elements are fully loaded\n",
    "time.sleep(3)\n",
    "\n",
    "# Extract article information with error handling\n",
    "data = []\n",
    "for article in articles:\n",
    "    try:\n",
    "        # Find elements with None handling\n",
    "        title_elem = article.find(\"h1\", class_=\"CardArticle__title\")\n",
    "        date_elem = article.find(\"p\", class_=\"CardArticle__date\")\n",
    "        type_elem = article.find(\"p\", class_=\"CardArticle__type\")\n",
    "        link_elem = article.find(\"a\", class_=\"CardArticle__wrapper\")\n",
    "        \n",
    "        # Extract data with None checks\n",
    "        title = title_elem.get_text(strip=True) if title_elem else None\n",
    "        publish_date = date_elem.get_text(strip=True) if date_elem else None\n",
    "        article_type = type_elem.get_text(strip=True) if type_elem else None\n",
    "        link = link_elem[\"href\"] if link_elem else None\n",
    "        \n",
    "        data.append({\n",
    "            \"Title\": title,\n",
    "            \"Type\": article_type,\n",
    "            \"Published Date\": publish_date,\n",
    "            \"Link\": link,\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159e75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and process the data\n",
    "def clean_publication_dates(df):\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Clean date strings and convert to datetime\n",
    "    df['Published Date'] = df['Published Date'].str.replace(\n",
    "        r'(Published on |Accepted on )', '', \n",
    "        regex=True\n",
    "    )\n",
    "    \n",
    "    # Convert to datetime with proper error handling\n",
    "    df['Published Date'] = pd.to_datetime(\n",
    "        df['Published Date'],\n",
    "        dayfirst=True,  # Assuming date format is DD/MM/YYYY\n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Extract year and handle missing values\n",
    "    df['Year'] = df['Published Date'].dt.strftime('%Y')\n",
    "    df['Year'] = df['Year'].fillna('2010')  # Fill missing years with 2014\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_research_articles(df):\n",
    "    # Filter for Original Research articles\n",
    "    research_df = df[df['Type'] == 'Original Research'].copy()\n",
    "    \n",
    "    # Reset index after filtering\n",
    "    research_df = research_df.reset_index(drop=True)\n",
    "    \n",
    "    return research_df\n",
    "\n",
    "# Process the dataframe\n",
    "processed_df = clean_publication_dates(df)\n",
    "\n",
    "# Filter for Original Research articles\n",
    "research_df = filter_research_articles(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7932307c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#link = \"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1487146/full\"\n",
    "#response = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfeac4ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#abstract_meta = soup.find('meta', attrs={'name': 'citation_abstract'})\n",
    "#abstract = abstract_meta['content']\n",
    "#abstract_text = re.search(r'<p>(.*?)</p>', abstract).group(1)\n",
    "#abstract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da64b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections = [\"Data availability statement\", \"Ethics statement\", \"Author contributions\"]\n",
    "#extracted_text = []\n",
    "#found_section = False\n",
    "\n",
    "# Traverse paragraphs until we reach the first target section\n",
    "#for paragraph in soup.find_all(['p', 'h2']):\n",
    "    # If we encounter any target section, stop the extraction\n",
    "#    if paragraph.name == 'h2' and paragraph.text.strip() in sections:\n",
    "#        found_section = True\n",
    "#        break\n",
    "#    elif paragraph.name == 'p':  # Accumulate text in paragraphs\n",
    "#        extracted_text.append(paragraph.text.strip())\n",
    "\n",
    "# Join and print the extracted text\n",
    "#result = \" \".join(extracted_text)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bda5c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#link = \"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1435688/full\"\n",
    "#response = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#paragraphs = soup.find_all('p')\n",
    "#paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2390d8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#abstract_meta = soup.find('meta', attrs={'name': 'citation_abstract'})\n",
    "#abstract = abstract_meta['content']\n",
    "#abstract_text = re.search(r'<p>(.*?)</p>', abstract).group(1)\n",
    "#abstract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1994fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections = [\"Data availability statement\", \"Ethics statement\", \"Author contributions\"]\n",
    "#extracted_text = []\n",
    "#found_section = False\n",
    "\n",
    "# Traverse paragraphs until we reach the first target section\n",
    "#for paragraph in soup.find_all(['p', 'h2']):\n",
    "    # If we encounter any target section, stop the extraction\n",
    "#    if paragraph.name == 'h2' and paragraph.text.strip() in sections:\n",
    "#        found_section = True\n",
    "#        break\n",
    "#    elif paragraph.name == 'p':  # Accumulate text in paragraphs\n",
    "#        extracted_text.append(paragraph.text.strip())\n",
    "\n",
    "# Join and print the extracted text\n",
    "#result = \" \".join(extracted_text)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce65f4a-4f71-466b-8c12-4ea6a19a7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 1/80\n",
      "Processing article 2/80\n",
      "Processing article 3/80\n",
      "Processing article 4/80\n",
      "Processing article 5/80\n",
      "Processing article 6/80\n",
      "Processing article 7/80\n",
      "Processing article 8/80\n",
      "Processing article 9/80\n",
      "Processing article 10/80\n",
      "Processing article 11/80\n",
      "Processing article 12/80\n",
      "Processing article 13/80\n",
      "Processing article 14/80\n",
      "Processing article 15/80\n",
      "Processing article 16/80\n",
      "Processing article 17/80\n",
      "Processing article 18/80\n",
      "Processing article 19/80\n",
      "Processing article 20/80\n",
      "Processing article 21/80\n",
      "Processing article 22/80\n",
      "Processing article 23/80\n",
      "Processing article 24/80\n",
      "Processing article 25/80\n",
      "Processing article 26/80\n",
      "Processing article 27/80\n",
      "Processing article 28/80\n",
      "Processing article 29/80\n",
      "Processing article 30/80\n",
      "Processing article 31/80\n",
      "Processing article 32/80\n",
      "Processing article 33/80\n",
      "Processing article 34/80\n",
      "Processing article 35/80\n",
      "Processing article 36/80\n",
      "Processing article 37/80\n",
      "Processing article 38/80\n",
      "Processing article 39/80\n",
      "Processing article 40/80\n",
      "Processing article 41/80\n",
      "Processing article 42/80\n",
      "Processing article 43/80\n",
      "Processing article 44/80\n",
      "Processing article 45/80\n",
      "Processing article 46/80\n",
      "Processing article 47/80\n",
      "Processing article 48/80\n",
      "Processing article 49/80\n",
      "Processing article 50/80\n",
      "Processing article 51/80\n",
      "Processing article 52/80\n",
      "Processing article 53/80\n",
      "Processing article 54/80\n",
      "Processing article 55/80\n",
      "Processing article 56/80\n",
      "Processing article 57/80\n",
      "Processing article 58/80\n",
      "Processing article 59/80\n",
      "Processing article 60/80\n",
      "Processing article 61/80\n",
      "Processing article 62/80\n",
      "Processing article 63/80\n",
      "Processing article 64/80\n",
      "Processing article 65/80\n",
      "Processing article 66/80\n",
      "Processing article 67/80\n",
      "Processing article 68/80\n",
      "Processing article 69/80\n",
      "Processing article 70/80\n",
      "Processing article 71/80\n",
      "Processing article 72/80\n",
      "Processing article 73/80\n",
      "Processing article 74/80\n",
      "Processing article 75/80\n",
      "Processing article 76/80\n",
      "Processing article 77/80\n",
      "Processing article 78/80\n",
      "Processing article 79/80\n",
      "Processing article 80/80\n",
      "\n",
      "Processing completed!\n",
      "Total articles processed: 80\n",
      "Articles with abstracts: 80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Link</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Several psychological theories assume that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;The aim of this study was to investigate th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Animals are notoriously impulsive in common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Music notations use both symbolic and spati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A small number of individuals have severe m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Previous studies recording eye gaze during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A model is proposed to characterize the typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Homosexuals are believed to have a “sixth s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Culture affects the way people move their e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;The interest in the influence of videogame ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title  Year                                               Link  \\\n",
       "0   None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "1   None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "2   None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "3   None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "4   None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "..   ...   ...                                                ...   \n",
       "75  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "76  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "77  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "78  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "79  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "\n",
       "                                             Abstract  \n",
       "0   <p>Several psychological theories assume that ...  \n",
       "1   <p>The aim of this study was to investigate th...  \n",
       "2   <p>Animals are notoriously impulsive in common...  \n",
       "3   <p>Music notations use both symbolic and spati...  \n",
       "4   <p>A small number of individuals have severe m...  \n",
       "..                                                ...  \n",
       "75  <p>Previous studies recording eye gaze during ...  \n",
       "76  <p>A model is proposed to characterize the typ...  \n",
       "77  <p>Homosexuals are believed to have a “sixth s...  \n",
       "78  <p>Culture affects the way people move their e...  \n",
       "79  <p>The interest in the influence of videogame ...  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[403, 408, 429, 500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retries)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    return session\n",
    "\n",
    "def extract_article_details(session, url, retries=3):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = session.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            ## Extract authors\n",
    "            #authors = soup.select('.authors .author-wrapper')\n",
    "            #author_list = [author.get_text(strip=True) for author in authors]\n",
    "            \n",
    "            # Extract abstract\n",
    "            abstract_meta = soup.find('meta', attrs={'name': 'citation_abstract'})\n",
    "            abstract = abstract_meta['content'] if abstract_meta else \"Abstract not available\"\n",
    "            \n",
    "            # Extract title from meta tag (more reliable)\n",
    "            title_meta = soup.find('meta', attrs={'name': 'citation_title'})\n",
    "            title = title_meta['content'] if title_meta else \"Title not available\"\n",
    "            \n",
    "            return {\n",
    "                'Title': title,\n",
    "                #'Authors': '; '.join(author_list) if author_list else \"Authors not available\",\n",
    "                'Abstract': abstract\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == retries - 1:\n",
    "                return {\n",
    "                    'Title': \"Error extracting title\",\n",
    "                    #'Authors': \"Error extracting authors\",\n",
    "                    'Abstract': \"Error extracting abstract\"\n",
    "                }\n",
    "            time.sleep(2 ** attempt)\n",
    "\n",
    "def process_articles(research_df):\n",
    "    session = create_session()\n",
    "    processed_data = []\n",
    "    total_articles = len(research_df)\n",
    "    \n",
    "    for idx, row in research_df.iterrows():\n",
    "        print(f\"Processing article {idx + 1}/{total_articles}\")\n",
    "        \n",
    "        article_data = {\n",
    "            'Title': row['Title'],\n",
    "            'Year': row['Year'],\n",
    "            'Link': row['Link']\n",
    "        }\n",
    "        \n",
    "        if row['Link']:\n",
    "            details = extract_article_details(session, row['Link'])\n",
    "            article_data.update({\n",
    "                #'Authors': details['Authors'],\n",
    "                'Abstract': details['Abstract']\n",
    "            })\n",
    "        else:\n",
    "            article_data.update({\n",
    "                #'Authors': \"Link not available\",\n",
    "                'Abstract': \"Link not available\"\n",
    "            })\n",
    "        \n",
    "        processed_data.append(article_data)\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Process the articles and create final dataset\n",
    "try:\n",
    "    if 'Title' not in research_df.columns or 'Year' not in research_df.columns or 'Link' not in research_df.columns:\n",
    "        raise ValueError(\"Required columns (Title, Year, Link) not found in research_df\")\n",
    "    \n",
    "    final_df = process_articles(research_df)\n",
    "    \n",
    "    print(\"\\nProcessing completed!\")\n",
    "    print(f\"Total articles processed: {len(final_df)}\")\n",
    "    #print(f\"Articles with authors: {final_df['Authors'].notna().sum()}\")\n",
    "    print(f\"Articles with abstracts: {final_df['Abstract'].notna().sum()}\")\n",
    "\n",
    "    # Display DataFrame using IPython display (for Jupyter)\n",
    "    from IPython.display import display\n",
    "    display(final_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during processing: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf499f89-6246-4173-8666-f8ae888f5db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Link</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Several psychological theories assume that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;The aim of this study was to investigate th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Animals are notoriously impulsive in common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;Music notations use both symbolic and spati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.frontiersin.org/journals/psycholog...</td>\n",
       "      <td>&lt;p&gt;A small number of individuals have severe m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title  Year                                               Link  \\\n",
       "0  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "1  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "2  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "3  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "4  None  2010  https://www.frontiersin.org/journals/psycholog...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  <p>Several psychological theories assume that ...  \n",
       "1  <p>The aim of this study was to investigate th...  \n",
       "2  <p>Animals are notoriously impulsive in common...  \n",
       "3  <p>Music notations use both symbolic and spati...  \n",
       "4  <p>A small number of individuals have severe m...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = final_df\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86c6f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "        \n",
    "    # Remove HTML tags (including <p> and </p>)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Remove parenthetical content\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    \n",
    "    # Remove numbers, asterisks, and daggers\n",
    "    text = re.sub(r'(\\d+|\\*|†)', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Clean Title and Abstract\n",
    "#result_df['Title'] = result_df['Title'].apply(clean_text)\n",
    "result_df['Abstract'] = result_df['Abstract'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32e2902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df['Authors'] = result_df['Authors'].apply(\n",
    "#    lambda x: re.sub(r'(\\d+|\\*|†)', '', x)  # Remove digits, asterisks, and dagger symbols\n",
    "#                .replace(\"??\", \"\")          # Remove any question marks\n",
    "#                .replace(\",,\", \",\")         # Consolidate multiple commas\n",
    "#                .replace(\", ,\", \",\")        # Remove spaced commas\n",
    "#                .replace(\"  \", \" \")         # Remove double spaces\n",
    "#                .replace(\", ,\", \",\")                # Remove any trailing commas or spaces\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7545a69-5c3b-4dd1-a78a-e229a5a31c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year                                           Abstract\n",
      "0   2010  Several psychological theories assume that the...\n",
      "1   2010  The aim of this study was to investigate the h...\n",
      "2   2010  Animals are notoriously impulsive in common la...\n",
      "3   2010  Music notations use both symbolic and spatial ...\n",
      "4   2010  A small number of individuals have severe musi...\n",
      "..   ...                                                ...\n",
      "75  2010  Previous studies recording eye gaze during fac...\n",
      "76  2010  A model is proposed to characterize the type o...\n",
      "77  2010  Homosexuals are believed to have a “sixth sens...\n",
      "78  2010  Culture affects the way people move their eyes...\n",
      "79  2010  The interest in the influence of videogame exp...\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df[['Year', 'Abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1da9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"articles_data_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5437233",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5437fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
