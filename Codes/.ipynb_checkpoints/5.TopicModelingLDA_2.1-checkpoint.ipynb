{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5f64aa-0237-4156-852f-06a5bee18aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hyemi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###' ################################################################################\n",
    "###'\n",
    "###' IMPORT LIBRARIES\n",
    "###'\n",
    "###'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "from keybert import KeyBERT\n",
    "\n",
    "import ast\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "### LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Phrases\n",
    "\n",
    "### BERT\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423ff230-c8d7-4c31-99d3-7f0646650f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = Path(r\"C:\\Users\\Hyemi\\Python\\TopicModeling\\Data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "embedding_files = [\n",
    "    \"articles_4_clustering1.csv\",\n",
    "    \"articles_4_clustering2.csv\",\n",
    "    \"articles_4_clustering3.csv\",\n",
    "    \"articles_4_clustering4.csv\"\n",
    "]\n",
    "\n",
    "embedding_file_paths = [data_dir / file for file in embedding_files]\n",
    "\n",
    "\n",
    "embedding_dfs = []\n",
    "for file_path in embedding_file_paths:\n",
    "    if file_path.exists():  # Check if the file exists before reading\n",
    "        embedding_dfs.append(pd.read_csv(file_path))\n",
    "\n",
    "df1a = embedding_dfs[0]\n",
    "df2a = embedding_dfs[1]\n",
    "df3a = embedding_dfs[2]\n",
    "df4a = embedding_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f328e8c-c40e-4d37-9d30-8f86782613b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_tokens</th>\n",
       "      <th>Abstract_join</th>\n",
       "      <th>Year_Group</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Embeddings_S</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster8</th>\n",
       "      <th>Cluster9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>We describe a corpus of speech taking place be...</td>\n",
       "      <td>['describe', 'corpus', 'speech', 'place', 'kor...</td>\n",
       "      <td>describe corpus speech place korean mother chi...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3425672054290771, 1.4400174617767334, 1.108...</td>\n",
       "      <td>[0.34810734772791113, 0.4677801044194296, 0.57...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>Although compassion in healthcare differs in i...</td>\n",
       "      <td>['compassion', 'healthcare', 'differ', 'import...</td>\n",
       "      <td>compassion healthcare differ important way com...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.5338462591171265, 1.530231237411499, 0.9366...</td>\n",
       "      <td>[0.7735476754291247, 0.8830654594875341, -0.47...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>This study explored the effect of learning str...</td>\n",
       "      <td>['explore', 'learn', 'strategy', 'student', 'o...</td>\n",
       "      <td>explore learn strategy student organization ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.4609277248382568, 1.5704612731933594, 0.914...</td>\n",
       "      <td>[0.6113632411120875, 1.0682582925833488, -0.60...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Using the Grounded theory, we took Chinese ent...</td>\n",
       "      <td>['ground', 'theory', 'chinese', 'entrepreneur'...</td>\n",
       "      <td>ground theory chinese entrepreneur object cons...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3701508045196533, 1.3691604137420654, 0.899...</td>\n",
       "      <td>[0.4094584220353579, 0.1416004922137856, -0.69...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>With the outbreak of the COVID- crisis, the pu...</td>\n",
       "      <td>['outbreak', 'covid', 'crisis', 'public', 'get...</td>\n",
       "      <td>outbreak covid crisis public getting epidemicr...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3461201190948486, 1.4608646631240845, 0.855...</td>\n",
       "      <td>[0.3560096910588494, 0.563747015822865, -0.964...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>2021</td>\n",
       "      <td>BackgroundThe literature shows the negative ps...</td>\n",
       "      <td>['backgroundthe', 'literature', 'negative', 'p...</td>\n",
       "      <td>backgroundthe literature negative psychologica...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.1762337684631348, 1.5237650871276855, 0.911...</td>\n",
       "      <td>[-0.02184927097153048, 0.853299522992328, -0.6...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>2021</td>\n",
       "      <td>This study investigated Chinese university stu...</td>\n",
       "      <td>['investigate', 'chinese', 'university', 'stud...</td>\n",
       "      <td>investigate chinese university student technol...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.7362575531005859, 1.1006767749786377, 0.979...</td>\n",
       "      <td>[-1.0004385186465743, -1.0943229847643705, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>2021</td>\n",
       "      <td>People often use concrete spatial terms to rep...</td>\n",
       "      <td>['people', 'concrete', 'spatial', 'term', 'rep...</td>\n",
       "      <td>people concrete spatial term represent time me...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3095670938491821, 1.082215428352356, 0.9239...</td>\n",
       "      <td>[0.2747089383671882, -1.1793069778938658, -0.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>2021</td>\n",
       "      <td>This study departs from existing work on board...</td>\n",
       "      <td>['depart', 'exist', 'work', 'board', 'gender',...</td>\n",
       "      <td>depart exist work board gender diversity corpo...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3322162628173828, 1.436128854751587, 0.8619...</td>\n",
       "      <td>[0.3250849188114781, 0.4498794951411282, -0.92...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>2021</td>\n",
       "      <td>Influenced by the growing urge of investigatin...</td>\n",
       "      <td>['influence', 'grow', 'urge', 'investigate', '...</td>\n",
       "      <td>influence grow urge investigate combined natur...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.2833529710769653, 1.378739833831787, 1.0708...</td>\n",
       "      <td>[0.21640383507657862, 0.1856978913672418, 0.34...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year                                           Abstract  \\\n",
       "0     2020  We describe a corpus of speech taking place be...   \n",
       "1     2020  Although compassion in healthcare differs in i...   \n",
       "2     2020  This study explored the effect of learning str...   \n",
       "3     2020  Using the Grounded theory, we took Chinese ent...   \n",
       "4     2020  With the outbreak of the COVID- crisis, the pu...   \n",
       "...    ...                                                ...   \n",
       "7097  2021  BackgroundThe literature shows the negative ps...   \n",
       "7098  2021  This study investigated Chinese university stu...   \n",
       "7099  2021  People often use concrete spatial terms to rep...   \n",
       "7100  2021  This study departs from existing work on board...   \n",
       "7101  2021  Influenced by the growing urge of investigatin...   \n",
       "\n",
       "                                        Abstract_tokens  \\\n",
       "0     ['describe', 'corpus', 'speech', 'place', 'kor...   \n",
       "1     ['compassion', 'healthcare', 'differ', 'import...   \n",
       "2     ['explore', 'learn', 'strategy', 'student', 'o...   \n",
       "3     ['ground', 'theory', 'chinese', 'entrepreneur'...   \n",
       "4     ['outbreak', 'covid', 'crisis', 'public', 'get...   \n",
       "...                                                 ...   \n",
       "7097  ['backgroundthe', 'literature', 'negative', 'p...   \n",
       "7098  ['investigate', 'chinese', 'university', 'stud...   \n",
       "7099  ['people', 'concrete', 'spatial', 'term', 'rep...   \n",
       "7100  ['depart', 'exist', 'work', 'board', 'gender',...   \n",
       "7101  ['influence', 'grow', 'urge', 'investigate', '...   \n",
       "\n",
       "                                          Abstract_join  Year_Group  \\\n",
       "0     describe corpus speech place korean mother chi...           3   \n",
       "1     compassion healthcare differ important way com...           3   \n",
       "2     explore learn strategy student organization ca...           3   \n",
       "3     ground theory chinese entrepreneur object cons...           3   \n",
       "4     outbreak covid crisis public getting epidemicr...           3   \n",
       "...                                                 ...         ...   \n",
       "7097  backgroundthe literature negative psychologica...           3   \n",
       "7098  investigate chinese university student technol...           3   \n",
       "7099  people concrete spatial term represent time me...           3   \n",
       "7100  depart exist work board gender diversity corpo...           3   \n",
       "7101  influence grow urge investigate combined natur...           3   \n",
       "\n",
       "                                             Embeddings  \\\n",
       "0     [1.3425672054290771, 1.4400174617767334, 1.108...   \n",
       "1     [1.5338462591171265, 1.530231237411499, 0.9366...   \n",
       "2     [1.4609277248382568, 1.5704612731933594, 0.914...   \n",
       "3     [1.3701508045196533, 1.3691604137420654, 0.899...   \n",
       "4     [1.3461201190948486, 1.4608646631240845, 0.855...   \n",
       "...                                                 ...   \n",
       "7097  [1.1762337684631348, 1.5237650871276855, 0.911...   \n",
       "7098  [0.7362575531005859, 1.1006767749786377, 0.979...   \n",
       "7099  [1.3095670938491821, 1.082215428352356, 0.9239...   \n",
       "7100  [1.3322162628173828, 1.436128854751587, 0.8619...   \n",
       "7101  [1.2833529710769653, 1.378739833831787, 1.0708...   \n",
       "\n",
       "                                           Embeddings_S  Cluster3  Cluster4  \\\n",
       "0     [0.34810734772791113, 0.4677801044194296, 0.57...         0         0   \n",
       "1     [0.7735476754291247, 0.8830654594875341, -0.47...         0         0   \n",
       "2     [0.6113632411120875, 1.0682582925833488, -0.60...         0         0   \n",
       "3     [0.4094584220353579, 0.1416004922137856, -0.69...         0         0   \n",
       "4     [0.3560096910588494, 0.563747015822865, -0.964...         0         1   \n",
       "...                                                 ...       ...       ...   \n",
       "7097  [-0.02184927097153048, 0.853299522992328, -0.6...         0         1   \n",
       "7098  [-1.0004385186465743, -1.0943229847643705, -0....         0         1   \n",
       "7099  [0.2747089383671882, -1.1793069778938658, -0.5...         0         1   \n",
       "7100  [0.3250849188114781, 0.4498794951411282, -0.92...         0         1   \n",
       "7101  [0.21640383507657862, 0.1856978913672418, 0.34...         0         1   \n",
       "\n",
       "      Cluster5  Cluster8  Cluster9  \n",
       "0            3         7         3  \n",
       "1            3         7         3  \n",
       "2            3         7         3  \n",
       "3            4         4         4  \n",
       "4            0         3         1  \n",
       "...        ...       ...       ...  \n",
       "7097         0         3         1  \n",
       "7098         0         3         1  \n",
       "7099         0         2         2  \n",
       "7100         0         3         1  \n",
       "7101         0         3         1  \n",
       "\n",
       "[7102 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ab317-ab38-49fe-8cc6-f2c82bef34d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c46674-c2eb-46b3-a372-ebb963f185da",
   "metadata": {},
   "source": [
    "## Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5ad77f-2289-4437-bb50-434441895004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster3\n",
      "0    3101\n",
      "1     862\n",
      "2     432\n",
      "Name: count, dtype: int64\n",
      "Cluster4\n",
      "0    2115\n",
      "3     986\n",
      "1     862\n",
      "2     432\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "0    1650\n",
      "3     986\n",
      "4     862\n",
      "1     465\n",
      "2     432\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1 = df1a\n",
    "print(df1['Cluster3'].value_counts())\n",
    "print(df1['Cluster4'].value_counts())\n",
    "print(df1['Cluster5'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f68ac9b-1098-4ec8-a728-2ac1414414a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: facial expression, individual difference, positive negative, old adult, control group, work memory, prosocial behavior, emotion regulation, mental health, negative emotion\n",
      "Cluster 1: work memory, executive function, control group, individual difference, old adult, working memory, speech perception, reaction time, second language, young adult\n",
      "Cluster 2: gender difference, spatial ability, stem career, stem field, engineering mathematic, woman engineering, gender gap, science technology, science technology engineering, science technology engineering mathematic\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df1['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df1['Cluster3'].astype(int).tolist() \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=4)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df1['Cluster3'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcac4f40-56b4-4235-8367-3fed63f726d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: facial expression, old adult, healthy control, individual difference, control group, experiment participant, reaction time, emotional expression, spatial frequency, work memory\n",
      "Cluster 1: speech perception, work memory, second language, auditory visual, native speaker, native language, speech sound, target word, individual difference, provide evidence\n",
      "Cluster 2: young child, prosocial behavior, executive function, work memory, control group, child adult, depressive symptom, individual difference, group child, mother child\n",
      "Cluster 3: physical activity, job satisfaction, psychological wellbeing, life satisfaction, academic achievement, structural equation, social support, confirmatory factor, individual difference, gender difference\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df1['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df1['Cluster4'].astype(int).tolist() \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df1['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ecc27-2230-4719-94c1-1b9cf9b138b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df1['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df1['Cluster5'].astype(int).tolist() \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df1['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e5e07-aa2e-44da-8daf-8e40a2b303a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796c72c-52f3-4972-89bb-64438dcc8079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2998e50-0973-4bca-b5f1-83f1846d21bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093e6554-1b10-48a4-854a-ac68170fd2b8",
   "metadata": {},
   "source": [
    "## Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8083def1-13b4-4b1c-87ee-924e519bb96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster3\n",
      "0    3387\n",
      "1    1432\n",
      "2     945\n",
      "Name: count, dtype: int64\n",
      "Cluster4\n",
      "0    2229\n",
      "1    1432\n",
      "3    1158\n",
      "2     945\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "3    1595\n",
      "0    1432\n",
      "1    1158\n",
      "2     945\n",
      "4     634\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2 = df2a\n",
    "print(df2['Cluster3'].value_counts())\n",
    "print(df2['Cluster4'].value_counts())\n",
    "print(df2['Cluster5'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c819c9be-f48b-4e2d-a2c8-2cbd90b57632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, work memory, old adult, control group, individual difference, executive function, structural equation, facial expression, positive negative, confirmatory factor\n",
      "Cluster 1: entrepreneurial intention, entrepreneurship education, entrepreneurial education, entrepreneurial follower, entrepreneurial orientation, entrepreneurial passion, dark triad, university student, student entrepreneurial, entrepreneurial selfefficacy\n",
      "Cluster 2: academic procrastination, utility value, bedtime procrastination, distal utility, distal utility value, team procrastination, procrastination scale, effort cost, peer attachment, selfregulatory resource\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df2['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df2['Cluster3'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=4)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df2['Cluster3'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a34bbc-036c-44ac-b40e-58b62ff5ae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, control group, work memory, facial expression, individual difference, structural equation, positive negative, executive function, old adult, confirmatory factor\n",
      "Cluster 1: entrepreneurial intention, entrepreneurship education, entrepreneurial follower, entrepreneurial education, entrepreneurial orientation, entrepreneurial passion, university student, dark triad, entrepreneurial selfefficacy, student entrepreneurial\n",
      "Cluster 2: pet dog, dog owner, ot avp, domestic dog, behavior dog, oxtr gene, fear response, wolf dog, assistance dog, avp dog\n",
      "Cluster 3: mobile advertising, intention purchase, purchase intention, design perception, plot story, price information, mobile shopping, consumer purchase, supplementary product, brand extension\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df2['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df2['Cluster4'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df2['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020b24be-abee-49b6-864c-bab9d5a2f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, depressive symptom, facial expression, positive negative, confirmatory factor, personality trait, social support, individual difference, psychometric property, man woman\n",
      "Cluster 1: work memory, old adult, executive function, working memory, child asd, reaction time, control group, young adult, typically develop, cognitive control\n",
      "Cluster 2: job satisfaction, structural equation, practical implication, mediate relationship, datum collect, work engagement, physical activity, transformational leadership, job demand, positively relate\n",
      "Cluster 3: mobile advertising, intention purchase, purchase intention, design perception, plot story, internet slang, price information, mobile shopping, consumer purchase, supplementary product\n",
      "Cluster 4: domestic dog, ot avp, comt valmet, avp dog, social behavior, behavior dog, dog owner, pet dog, gaze behavior, japanese dog\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df2['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df2['Cluster5'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df2['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991b038-7e46-48e6-9811-75a47fa26774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d16fd4-2e91-48a5-b0e3-19a3fad9d068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc72383-06a7-4426-b413-cee84008b1c2",
   "metadata": {},
   "source": [
    "## GROUP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a455e89-dd2e-4c03-bfea-55a1362fd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3a\n",
    "print(df3['Cluster4'].value_counts())\n",
    "print(df3['Cluster5'].value_counts())\n",
    "print(df3['Cluster8'].value_counts())\n",
    "print(df3['Cluster9'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abd2a04-aec3-4a76-9fe1-0ac33a7655e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, physical activity, college student, structural equation, social support, datum collect, university student, work engagement, mediate relationship\n",
      "Cluster 1: native speaker, old adult, second language, work memory, cognitive control, control group, reaction time, executive function, read comprehension, phonological awareness\n",
      "Cluster 2: soccer player, football player, elite athlete, mental health, physical activity, futsal player, sport performance, significant difference, covid pandemic, goal motive\n",
      "Cluster 3: sample size, cognitive diagnostic, item response, cognitive diagnosis, monte carlo, parameter estimate, classification accuracy, item parameter, cognitive diagnosis model, diagnosis model\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster4'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f84cd13-f922-45f8-9d1f-6ae670ca3872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, physical activity, college student, structural equation, social support, university student, datum collect, work engagement, depressive symptom\n",
      "Cluster 1: purchase intention, old adult, facial expression, native speaker, social medium, second language, control group, climate change, cognitive control, eye movement\n",
      "Cluster 2: soccer player, football player, physical activity, elite athlete, mental health, sport performance, significant difference, futsal player, covid pandemic, goal motive\n",
      "Cluster 3: sample size, cognitive diagnostic, cognitive diagnosis, monte carlo, item response, parameter estimate, classification accuracy, item parameter, cognitive diagnosis model, diagnosis model\n",
      "Cluster 4: tourism experience, tourism development, poverty alleviation, tourism product, tourism industry, visually impair, tourist satisfaction, sustainable tourism, place attachment, cultural heritage\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster5'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45652d6-31f5-4351-92b1-67a29c0bc645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, physical activity, structural equation, social support, college student, university student, control group, negative emotion, depressive symptom\n",
      "Cluster 1: native speaker, phonological awareness, second language, read comprehension, word recognition, target word, phonological processing, word order, clause chain, language comprehension\n",
      "Cluster 2: soccer player, football player, sport performance, elite athlete, mental health, goal motive, physical activity, futsal player, team sport, significant difference\n",
      "Cluster 3: music student, music performance, acoustic environment, music listen, musical instrument, musical experience, old adult, performance anxiety, music therapy, instrumental music\n",
      "Cluster 4: entrepreneurship education, entrepreneurial intention, college student, innovation entrepreneurship, student entrepreneurial, entrepreneurial selfefficacy, new venture, psychological capital, entrepreneurial psychology, innovation behavior\n",
      "Cluster 5: communicative act, gender stereotype, male female, gender difference, gender role, sexual orientation, gender equality, sexual behavior, man woman, parenting intention\n",
      "Cluster 6: sample size, latent class, cognitive diagnostic, cognitive diagnosis, item response, classification accuracy, parameter estimate, monte carlo, diagnosis model, cognitive diagnosis model\n",
      "Cluster 7: ego depletion, interpersonal forgiveness, leader narcissism, vulnerable narcissism, offense situation, forgiveness intervention, emotion regulation, implicit forgiveness, team voice, love forgiveness\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster8'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=9)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster8'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60093be-4dee-40a2-b7c4-e09dd38c675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, physical activity, social support, depression anxiety, anxiety depression, depressive symptom, online survey, psychological wellbeing, university student\n",
      "Cluster 1: mental health, executive function, child adolescent, parent child, covid pandemic, young child, emotion regulation, college student, structural equation, control group\n",
      "Cluster 2: entrepreneurship education, entrepreneurial intention, college student, structural equation, datum collect, moderate relationship, work engagement, psychological capital, practical implication, purchase intention\n",
      "Cluster 3: facial expression, native speaker, second language, work memory, visual attention, eye movement, individual difference, old adult, control group, emotion recognition\n",
      "Cluster 4: soccer player, elite athlete, football player, sport performance, futsal player, mental health, significant difference, physical activity, team sport, covid pandemic\n",
      "Cluster 5: music student, music performance, acoustic environment, music listen, musical instrument, musical experience, frequency band, performance anxiety, old adult, music therapy\n",
      "Cluster 6: gender stereotype, stereotype threat, communicative act, man woman, male female, child sexual, gender role, gender difference, united states, partner violence\n",
      "Cluster 7: cognitive diagnostic, sample size, latent class, cognitive diagnosis, item response, classification accuracy, parameter estimate, diagnosis model, cognitive diagnosis model, item parameter\n",
      "Cluster 8: interpersonal forgiveness, offense situation, forgiveness intervention, explicit forgiveness, love forgiveness, implicit forgiveness, trait forgiveness, forgiveness tendency, emotional forgiveness, trait anger\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster9'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=10)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster9'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9be0e-e7b9-4e10-b486-2a131587c36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881a0be-8315-4fd6-985b-5ab55f4766fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c7d02b2-97ba-4f68-970d-6429a478ecd3",
   "metadata": {},
   "source": [
    "## GROUP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193aef34-4cfa-485f-a78a-6c9f006be948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster4\n",
      "0    3407\n",
      "2    3265\n",
      "3    3042\n",
      "1    2461\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "0    3265\n",
      "3    3042\n",
      "1    2461\n",
      "2    2057\n",
      "4    1350\n",
      "Name: count, dtype: int64\n",
      "Cluster9\n",
      "0    3042\n",
      "2    2193\n",
      "5    1972\n",
      "4    1350\n",
      "1    1036\n",
      "3    1021\n",
      "8     647\n",
      "7     646\n",
      "6     268\n",
      "Name: count, dtype: int64\n",
      "Cluster10\n",
      "3    2266\n",
      "2    2193\n",
      "5    1972\n",
      "9    1350\n",
      "0    1036\n",
      "1    1021\n",
      "4     776\n",
      "8     647\n",
      "7     646\n",
      "6     268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df4 = df4a\n",
    "print(df4['Cluster4'].value_counts())\n",
    "print(df4['Cluster5'].value_counts())\n",
    "print(df4['Cluster9'].value_counts())\n",
    "print(df4['Cluster10'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb9d3e5-6d1d-458e-8656-c7f933dbb1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, college student, covid pandemic, social support, physical activity, structural equation, university student, datum collect, control group, mediate relationship\n",
      "Cluster 1: entrepreneurial intention, purchase intention, structural equation, entrepreneurship education, college student, innovation performance, equation modeling, consumer purchase, significant positive, datum collect\n",
      "Cluster 2: covid vaccine, covid vaccination, vaccination intention, vaccine uptake, vaccine hesitancy, covid vaccination intention, information need, covid vaccine uptake, fear covid, vaccine information\n",
      "Cluster 3: psychedelic experience, attribution consciousness, archetype symbol, time travel, increase attribution, time travel past, category comprise, increase attribution consciousness, neardeath experience, travel past\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster4'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2358a7a3-69c7-4d9d-8d26-5928037592c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, college student, covid pandemic, structural equation, social support, datum collect, social medium, physical activity, mediate relationship, university student\n",
      "Cluster 1: old adult, facial expression, emotion recognition, work memory, executive function, significant difference, young adult, second language, reaction time, control group\n",
      "Cluster 2: elite athlete, soccer player, mental toughness, mental health, athlete burnout, athlete leadership, sport performance, significant difference, team sport, match performance\n",
      "Cluster 3: academic procrastination, video addiction, short video addiction, physical activity, short video, work procrastination, time management, college student, procrastination behavior, procrastination scale\n",
      "Cluster 4: covid vaccine, covid vaccination, vaccination intention, vaccine uptake, covid vaccination intention, vaccine hesitancy, information need, covid vaccine uptake, fear covid, vaccine information\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster5'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40741099-1599-4b73-90a7-b1cc3e78e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, social support, college student, physical activity, depressive symptom, covid pandemic, quality life, sleep quality, social medium, anxiety depression\n",
      "Cluster 1: entrepreneurial intention, structural equation, purchase intention, social medium, datum collect, practical implication, equation modeling, moderate relationship, moderate role, mediate relationship\n",
      "Cluster 2: old adult, facial expression, emotion recognition, executive function, work memory, second language, significant difference, young adult, control group, sign language\n",
      "Cluster 3: foreign language, college student, online learning, university student, structural equation, academic performance, efl teacher, preservice teacher, student learn, english foreign\n",
      "Cluster 4: music education, music performance, music listen, music training, music therapy, music teacher, performance anxiety, mental health, music performance anxiety, public performance\n",
      "Cluster 5: athlete burnout, mental toughness, soccer player, elite athlete, motor imagery, motor skill, significant difference, psychological resilience, coaching style, personality trait\n",
      "Cluster 6: academic procrastination, video addiction, work procrastination, short video addiction, physical activity, short video, maladaptive perfectionism, college student, time management, procrastination scale\n",
      "Cluster 7: fit index, type error, sample size, type error rate, error rate, pglogit model, free model, rate false, residual variance, model evaluation\n",
      "Cluster 8: psychedelic experience, mindfulness meditation, mindfulness meditation psychedelic, meditation psychedelic, attribution consciousness, archetype symbol, challenging experience, psychedelic drug, psychedelic integration, mystical experience\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster9'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=10)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster9'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5bc9625-eca9-4246-9258-46c1526fe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, college student, physical activity, social support, depressive symptom, covid pandemic, old adult, quality life, social medium, life satisfaction\n",
      "Cluster 1: college student, entrepreneurial intention, structural equation, covid pandemic, work engagement, datum collect, entrepreneurship education, university student, mediate relationship, job satisfaction\n",
      "Cluster 2: purchase intention, social medium, structural equation, green innovation, consumer purchase, climate change, equation modeling, sustainable development, perceive value, consumer purchase intention\n",
      "Cluster 3: facial expression, emotion recognition, old adult, second language, significant difference, young adult, speech perception, neural network, heritage speaker, individual difference\n",
      "Cluster 4: parent child, young child, mental health, parenting style, preschool child, early childhood, social support, executive function, child asd, control group\n",
      "Cluster 5: athlete burnout, soccer player, mental toughness, state anxiety, sport performance, elite athlete, athlete engagement, competitive anxiety, coachathlete relationship, significant difference\n",
      "Cluster 6: music education, music therapy, music training, music teacher, music listen, music performance, mental health, performance anxiety, music performance anxiety, music perception\n",
      "Cluster 7: corporate governance, stock market, stock liquidity, social responsibility, investment decision, corporate social, financial performance, corporate social responsibility, firm performance, digital finance\n",
      "Cluster 8: academic procrastination, work procrastination, short video addiction, video addiction, short video, physical activity, maladaptive perfectionism, time management, college student, procrastination scale\n",
      "Cluster 9: psychedelic experience, mindfulness meditation, attribution consciousness, meditation psychedelic, mindfulness meditation psychedelic, santo daime, psychedelic humanity, cognitive liberty, archetype symbol, challenging experience\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster10'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=11)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster10'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
