{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5f64aa-0237-4156-852f-06a5bee18aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hyemi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###' ################################################################################\n",
    "###'\n",
    "###' IMPORT LIBRARIES\n",
    "###'\n",
    "###'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "from keybert import KeyBERT\n",
    "\n",
    "import ast\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "### LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Phrases\n",
    "\n",
    "### BERT\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423ff230-c8d7-4c31-99d3-7f0646650f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = Path(r\"C:\\Users\\Hyemi\\Python\\TopicModeling\\Data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "embedding_files = [\n",
    "    \"articles_4_clustering1.csv\",\n",
    "    \"articles_4_clustering2.csv\",\n",
    "    \"articles_4_clustering3.csv\",\n",
    "    \"articles_4_clustering4.csv\"\n",
    "]\n",
    "\n",
    "embedding_file_paths = [data_dir / file for file in embedding_files]\n",
    "\n",
    "\n",
    "embedding_dfs = []\n",
    "for file_path in embedding_file_paths:\n",
    "    if file_path.exists():  # Check if the file exists before reading\n",
    "        embedding_dfs.append(pd.read_csv(file_path))\n",
    "\n",
    "df1a = embedding_dfs[0]\n",
    "df2a = embedding_dfs[1]\n",
    "df3a = embedding_dfs[2]\n",
    "df4a = embedding_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f328e8c-c40e-4d37-9d30-8f86782613b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_tokens</th>\n",
       "      <th>Abstract_join</th>\n",
       "      <th>Year_Group</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Embeddings_S</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster8</th>\n",
       "      <th>Cluster9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>We describe a corpus of speech taking place be...</td>\n",
       "      <td>['describe', 'corpus', 'speech', 'place', 'kor...</td>\n",
       "      <td>describe corpus speech place korean mother chi...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3425672054290771, 1.4400174617767334, 1.108...</td>\n",
       "      <td>[0.34810734772791113, 0.4677801044194296, 0.57...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>Although compassion in healthcare differs in i...</td>\n",
       "      <td>['compassion', 'healthcare', 'differ', 'import...</td>\n",
       "      <td>compassion healthcare differ important way com...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.5338462591171265, 1.530231237411499, 0.9366...</td>\n",
       "      <td>[0.7735476754291247, 0.8830654594875341, -0.47...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>This study explored the effect of learning str...</td>\n",
       "      <td>['explore', 'learn', 'strategy', 'student', 'o...</td>\n",
       "      <td>explore learn strategy student organization ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.4609277248382568, 1.5704612731933594, 0.914...</td>\n",
       "      <td>[0.6113632411120875, 1.0682582925833488, -0.60...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Using the Grounded theory, we took Chinese ent...</td>\n",
       "      <td>['ground', 'theory', 'chinese', 'entrepreneur'...</td>\n",
       "      <td>ground theory chinese entrepreneur object cons...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3701508045196533, 1.3691604137420654, 0.899...</td>\n",
       "      <td>[0.4094584220353579, 0.1416004922137856, -0.69...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>With the outbreak of the COVID- crisis, the pu...</td>\n",
       "      <td>['outbreak', 'covid', 'crisis', 'public', 'get...</td>\n",
       "      <td>outbreak covid crisis public getting epidemicr...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3461201190948486, 1.4608646631240845, 0.855...</td>\n",
       "      <td>[0.3560096910588494, 0.563747015822865, -0.964...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>2021</td>\n",
       "      <td>BackgroundThe literature shows the negative ps...</td>\n",
       "      <td>['backgroundthe', 'literature', 'negative', 'p...</td>\n",
       "      <td>backgroundthe literature negative psychologica...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.1762337684631348, 1.5237650871276855, 0.911...</td>\n",
       "      <td>[-0.02184927097153048, 0.853299522992328, -0.6...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>2021</td>\n",
       "      <td>This study investigated Chinese university stu...</td>\n",
       "      <td>['investigate', 'chinese', 'university', 'stud...</td>\n",
       "      <td>investigate chinese university student technol...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.7362575531005859, 1.1006767749786377, 0.979...</td>\n",
       "      <td>[-1.0004385186465743, -1.0943229847643705, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>2021</td>\n",
       "      <td>People often use concrete spatial terms to rep...</td>\n",
       "      <td>['people', 'concrete', 'spatial', 'term', 'rep...</td>\n",
       "      <td>people concrete spatial term represent time me...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3095670938491821, 1.082215428352356, 0.9239...</td>\n",
       "      <td>[0.2747089383671882, -1.1793069778938658, -0.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>2021</td>\n",
       "      <td>This study departs from existing work on board...</td>\n",
       "      <td>['depart', 'exist', 'work', 'board', 'gender',...</td>\n",
       "      <td>depart exist work board gender diversity corpo...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.3322162628173828, 1.436128854751587, 0.8619...</td>\n",
       "      <td>[0.3250849188114781, 0.4498794951411282, -0.92...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>2021</td>\n",
       "      <td>Influenced by the growing urge of investigatin...</td>\n",
       "      <td>['influence', 'grow', 'urge', 'investigate', '...</td>\n",
       "      <td>influence grow urge investigate combined natur...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.2833529710769653, 1.378739833831787, 1.0708...</td>\n",
       "      <td>[0.21640383507657862, 0.1856978913672418, 0.34...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year                                           Abstract  \\\n",
       "0     2020  We describe a corpus of speech taking place be...   \n",
       "1     2020  Although compassion in healthcare differs in i...   \n",
       "2     2020  This study explored the effect of learning str...   \n",
       "3     2020  Using the Grounded theory, we took Chinese ent...   \n",
       "4     2020  With the outbreak of the COVID- crisis, the pu...   \n",
       "...    ...                                                ...   \n",
       "7097  2021  BackgroundThe literature shows the negative ps...   \n",
       "7098  2021  This study investigated Chinese university stu...   \n",
       "7099  2021  People often use concrete spatial terms to rep...   \n",
       "7100  2021  This study departs from existing work on board...   \n",
       "7101  2021  Influenced by the growing urge of investigatin...   \n",
       "\n",
       "                                        Abstract_tokens  \\\n",
       "0     ['describe', 'corpus', 'speech', 'place', 'kor...   \n",
       "1     ['compassion', 'healthcare', 'differ', 'import...   \n",
       "2     ['explore', 'learn', 'strategy', 'student', 'o...   \n",
       "3     ['ground', 'theory', 'chinese', 'entrepreneur'...   \n",
       "4     ['outbreak', 'covid', 'crisis', 'public', 'get...   \n",
       "...                                                 ...   \n",
       "7097  ['backgroundthe', 'literature', 'negative', 'p...   \n",
       "7098  ['investigate', 'chinese', 'university', 'stud...   \n",
       "7099  ['people', 'concrete', 'spatial', 'term', 'rep...   \n",
       "7100  ['depart', 'exist', 'work', 'board', 'gender',...   \n",
       "7101  ['influence', 'grow', 'urge', 'investigate', '...   \n",
       "\n",
       "                                          Abstract_join  Year_Group  \\\n",
       "0     describe corpus speech place korean mother chi...           3   \n",
       "1     compassion healthcare differ important way com...           3   \n",
       "2     explore learn strategy student organization ca...           3   \n",
       "3     ground theory chinese entrepreneur object cons...           3   \n",
       "4     outbreak covid crisis public getting epidemicr...           3   \n",
       "...                                                 ...         ...   \n",
       "7097  backgroundthe literature negative psychologica...           3   \n",
       "7098  investigate chinese university student technol...           3   \n",
       "7099  people concrete spatial term represent time me...           3   \n",
       "7100  depart exist work board gender diversity corpo...           3   \n",
       "7101  influence grow urge investigate combined natur...           3   \n",
       "\n",
       "                                             Embeddings  \\\n",
       "0     [1.3425672054290771, 1.4400174617767334, 1.108...   \n",
       "1     [1.5338462591171265, 1.530231237411499, 0.9366...   \n",
       "2     [1.4609277248382568, 1.5704612731933594, 0.914...   \n",
       "3     [1.3701508045196533, 1.3691604137420654, 0.899...   \n",
       "4     [1.3461201190948486, 1.4608646631240845, 0.855...   \n",
       "...                                                 ...   \n",
       "7097  [1.1762337684631348, 1.5237650871276855, 0.911...   \n",
       "7098  [0.7362575531005859, 1.1006767749786377, 0.979...   \n",
       "7099  [1.3095670938491821, 1.082215428352356, 0.9239...   \n",
       "7100  [1.3322162628173828, 1.436128854751587, 0.8619...   \n",
       "7101  [1.2833529710769653, 1.378739833831787, 1.0708...   \n",
       "\n",
       "                                           Embeddings_S  Cluster3  Cluster4  \\\n",
       "0     [0.34810734772791113, 0.4677801044194296, 0.57...         0         0   \n",
       "1     [0.7735476754291247, 0.8830654594875341, -0.47...         0         0   \n",
       "2     [0.6113632411120875, 1.0682582925833488, -0.60...         0         0   \n",
       "3     [0.4094584220353579, 0.1416004922137856, -0.69...         0         0   \n",
       "4     [0.3560096910588494, 0.563747015822865, -0.964...         0         1   \n",
       "...                                                 ...       ...       ...   \n",
       "7097  [-0.02184927097153048, 0.853299522992328, -0.6...         0         1   \n",
       "7098  [-1.0004385186465743, -1.0943229847643705, -0....         0         1   \n",
       "7099  [0.2747089383671882, -1.1793069778938658, -0.5...         0         1   \n",
       "7100  [0.3250849188114781, 0.4498794951411282, -0.92...         0         1   \n",
       "7101  [0.21640383507657862, 0.1856978913672418, 0.34...         0         1   \n",
       "\n",
       "      Cluster5  Cluster8  Cluster9  \n",
       "0            3         7         3  \n",
       "1            3         7         3  \n",
       "2            3         7         3  \n",
       "3            4         4         4  \n",
       "4            0         3         1  \n",
       "...        ...       ...       ...  \n",
       "7097         0         3         1  \n",
       "7098         0         3         1  \n",
       "7099         0         2         2  \n",
       "7100         0         3         1  \n",
       "7101         0         3         1  \n",
       "\n",
       "[7102 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ab317-ab38-49fe-8cc6-f2c82bef34d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c46674-c2eb-46b3-a372-ebb963f185da",
   "metadata": {},
   "source": [
    "## Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5ad77f-2289-4437-bb50-434441895004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster3\n",
      "0    3101\n",
      "1     862\n",
      "2     432\n",
      "Name: count, dtype: int64\n",
      "Cluster4\n",
      "0    2115\n",
      "3     986\n",
      "1     862\n",
      "2     432\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "0    1650\n",
      "3     986\n",
      "4     862\n",
      "1     465\n",
      "2     432\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1 = df1a\n",
    "print(df1['Cluster3'].value_counts())\n",
    "print(df1['Cluster4'].value_counts())\n",
    "print(df1['Cluster5'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f68ac9b-1098-4ec8-a728-2ac1414414a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: work memory, facial expression, individual difference, old adult, control group, executive function, young adult, reaction time, positive negative, provide evidence\n",
      "Cluster 1: music training, musical training, speech music, phonological awareness, listen music, music language, program note, music speech, music performance, emotional response\n",
      "Cluster 2: gender difference, spatial ability, role noun, gender information, noun phrase, reflexive pronoun, grammatical gender, genderfair language, stem career, man woman\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df1['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df1['Cluster3'].astype(int).tolist() \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=4)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df1['Cluster3'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcac4f40-56b4-4235-8367-3fed63f726d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: work memory, individual difference, facial expression, control group, old adult, executive function, reaction time, experiment participant, provide evidence, participant perform\n",
      "Cluster 1: job satisfaction, prosocial behavior, depressive symptom, social support, physical activity, adult attachment, mental health, attachment style, individual difference, confirmatory factor\n",
      "Cluster 2: music training, speech music, musical training, piano performance, music performance, music perception, program note, music speech, expressive bodily, bodily movement\n",
      "Cluster 3: spatial frequency, cortical area, luminance step, figure ground, grid cell, surface quality, color discrimination, contour shape, local contour, border ownership\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df1['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df1['Cluster4'].astype(int).tolist() \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df1['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7ecc27-2230-4719-94c1-1b9cf9b138b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: facial expression, individual difference, work memory, control group, executive function, old adult, depressive symptom, positive negative, young adult, reaction time\n",
      "Cluster 1: work memory, speech perception, second language, auditory visual, native speaker, speech sound, lexical decision, musical training, eventrelate potential, word recognition\n",
      "Cluster 2: gender difference, spatial ability, stem career, stem field, engineering mathematic, word pair, woman engineering, angrymale bias, gender gap, science technology\n",
      "Cluster 3: zebra finch, selfother integration, vocal interaction, wolf dog, social network, fuzzy clustering, social structure, spatial distribution, physical size, social learning\n",
      "Cluster 4: odor pleasantness, olfactory receptor, body odor, auditory modality, olfactory cognition, fragrance condition, sign disorder, anterior medial, odor identification, pleasantness rating\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df1['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df1['Cluster5'].astype(int).tolist() \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df1['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e5e07-aa2e-44da-8daf-8e40a2b303a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796c72c-52f3-4972-89bb-64438dcc8079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2998e50-0973-4bca-b5f1-83f1846d21bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093e6554-1b10-48a4-854a-ac68170fd2b8",
   "metadata": {},
   "source": [
    "## Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8083def1-13b4-4b1c-87ee-924e519bb96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster3\n",
      "0    3387\n",
      "1    1432\n",
      "2     945\n",
      "Name: count, dtype: int64\n",
      "Cluster4\n",
      "0    2229\n",
      "1    1432\n",
      "3    1158\n",
      "2     945\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "3    1595\n",
      "0    1432\n",
      "1    1158\n",
      "2     945\n",
      "4     634\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2 = df2a\n",
    "print(df2['Cluster3'].value_counts())\n",
    "print(df2['Cluster4'].value_counts())\n",
    "print(df2['Cluster5'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c819c9be-f48b-4e2d-a2c8-2cbd90b57632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, control group, old adult, work memory, facial expression, structural equation, executive function, confirmatory factor, positive negative, individual difference\n",
      "Cluster 1: lexical tone, work memory, second language, bilingual child, relative clause, inhibitory control, novel word, language dominance, old adult, speech perception\n",
      "Cluster 2: academic procrastination, utility value, bedtime procrastination, distal utility, distal utility value, procrastination scale, team procrastination, effort cost, peer attachment, selfregulatory resource\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df2['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df2['Cluster3'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=4)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df2['Cluster3'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a34bbc-036c-44ac-b40e-58b62ff5ae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, work memory, control group, executive function, old adult, structural equation, facial expression, individual difference, positive negative, confirmatory factor\n",
      "Cluster 1: entrepreneurial intention, entrepreneurship education, entrepreneurial follower, entrepreneurial education, entrepreneurial orientation, entrepreneurial passion, university student, dark triad, entrepreneurial selfefficacy, student entrepreneurial\n",
      "Cluster 2: pet dog, dog owner, domestic dog, ot avp, behavior dog, oxtr gene, fear response, avp dog, assistance dog, wolf dog\n",
      "Cluster 3: rewarddelay impulsivity, adolescent gambling, venue terminal, cognitive distortion, net loss, rapidresponse impulsivity, dysfunctional impulsivity, gambling behavior, impulsivity rewarddelay impulsivity, deposit limit\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df2['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df2['Cluster4'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df2['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020b24be-abee-49b6-864c-bab9d5a2f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: facial expression, mental health, positive negative, emotion regulation, personality trait, depressive symptom, eat disorder, man woman, social support, gender difference\n",
      "Cluster 1: structural equation, work engagement, job satisfaction, mediate relationship, confirmatory factor, practical implication, datum collect, equation modeling, structural equation modeling, physical activity\n",
      "Cluster 2: work memory, old adult, executive function, working memory, child asd, reaction time, control group, young adult, typically develop, cognitive control\n",
      "Cluster 3: musical instrument, music performance, acoustic feature, musical training, practice session, music listen, musical feature, music training, group music, musical excerpt\n",
      "Cluster 4: domestic dog, ot avp, avp dog, comt valmet, social behavior, behavior dog, dog owner, pet dog, gaze behavior, japanese dog\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "abstracts = df2['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df2['Cluster5'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df2['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991b038-7e46-48e6-9811-75a47fa26774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d16fd4-2e91-48a5-b0e3-19a3fad9d068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc72383-06a7-4426-b413-cee84008b1c2",
   "metadata": {},
   "source": [
    "## GROUP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a455e89-dd2e-4c03-bfea-55a1362fd1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster4\n",
      "1    3029\n",
      "3    1932\n",
      "0    1467\n",
      "2     674\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "0    3029\n",
      "1    1932\n",
      "3    1283\n",
      "2     674\n",
      "4     184\n",
      "Name: count, dtype: int64\n",
      "Cluster8\n",
      "3    1683\n",
      "6    1290\n",
      "7    1283\n",
      "2     747\n",
      "5     674\n",
      "0     642\n",
      "1     599\n",
      "4     184\n",
      "Name: count, dtype: int64\n",
      "Cluster9\n",
      "1    1683\n",
      "6    1290\n",
      "3    1283\n",
      "2     747\n",
      "5     674\n",
      "0     599\n",
      "8     351\n",
      "7     291\n",
      "4     184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df3 = df3a\n",
    "print(df3['Cluster4'].value_counts())\n",
    "print(df3['Cluster5'].value_counts())\n",
    "print(df3['Cluster8'].value_counts())\n",
    "print(df3['Cluster9'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abd2a04-aec3-4a76-9fe1-0ac33a7655e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, physical activity, college student, structural equation, social support, university student, datum collect, entrepreneurship education, depressive symptom\n",
      "Cluster 1: facial expression, purchase intention, old adult, social medium, native speaker, second language, work memory, significant difference, eye movement, cognitive control\n",
      "Cluster 2: soccer player, football player, elite athlete, mental health, futsal player, significant difference, sport performance, physical activity, covid pandemic, team sport\n",
      "Cluster 3: music student, music performance, music listen, acoustic environment, musical experience, music therapy, performance anxiety, aesthetic judgment, instrumental music, musical performance\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster4'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f84cd13-f922-45f8-9d1f-6ae670ca3872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, college student, physical activity, structural equation, social support, university student, work engagement, datum collect, depressive symptom\n",
      "Cluster 1: purchase intention, facial expression, old adult, second language, native speaker, work memory, social medium, cognitive control, individual difference, climate change\n",
      "Cluster 2: soccer player, physical activity, football player, elite athlete, mental health, sport performance, futsal player, significant difference, covid pandemic, goal motive\n",
      "Cluster 3: music student, music performance, music listen, performance anxiety, old adult, musical experience, musical performance, music therapy, aesthetic judgment, instrumental music\n",
      "Cluster 4: virtual reality, art psychomotor, psychomotor therapy, art psychomotor therapy, shot performance, motion sickness, vr health, immersive experience, successful aging, vr health experience\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster5'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45652d6-31f5-4351-92b1-67a29c0bc645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, covid pandemic, physical activity, social support, structural equation, work engagement, university student, life satisfaction, college student, depressive symptom\n",
      "Cluster 1: facial expression, old adult, native speaker, negative emotion, individual difference, work memory, social medium, emotion regulation, control group, second language\n",
      "Cluster 2: entrepreneurship education, entrepreneurial intention, purchase intention, college student, innovation entrepreneurship, structural equation, student entrepreneurial, entrepreneurial selfefficacy, psychological capital, new venture\n",
      "Cluster 3: soccer player, football player, sport performance, elite athlete, mental health, physical activity, goal motive, futsal player, team sport, significant difference\n",
      "Cluster 4: music student, music performance, acoustic environment, music listen, musical instrument, musical experience, old adult, frequency band, performance anxiety, music therapy\n",
      "Cluster 5: communicative act, gender stereotype, male female, gender role, sexual orientation, gender equality, man woman, gender difference, sexual behavior, parenting intention\n",
      "Cluster 6: sample size, cognitive diagnostic, latent class, cognitive diagnosis, item response, classification accuracy, parameter estimate, monte carlo, cognitive diagnosis model, diagnosis model\n",
      "Cluster 7: interpersonal forgiveness, leader narcissism, vulnerable narcissism, offense situation, ego depletion, forgiveness intervention, emotion regulation, implicit forgiveness, explicit forgiveness, team voice\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster8'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=9)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster8'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60093be-4dee-40a2-b7c4-e09dd38c675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: entrepreneurship education, college student, work engagement, entrepreneurial intention, structural equation, datum collect, psychological capital, job satisfaction, mediate relationship, moderate relationship\n",
      "Cluster 1: mental health, covid pandemic, physical activity, depression anxiety, anxiety depression, social support, depressive symptom, online survey, perceive stress, coronavirus disease\n",
      "Cluster 2: native speaker, second language, work memory, visual attention, old adult, control group, word recognition, individual difference, clause chain, significant difference\n",
      "Cluster 3: social medium, purchase intention, facial expression, climate change, emotion recognition, emotion regulation, structural equation, perceive value, gender stereotype, datum collect\n",
      "Cluster 4: mental health, executive function, depressive symptom, child adolescent, young child, parent child, social anxiety, child asd, autism spectrum, college student\n",
      "Cluster 5: soccer player, elite athlete, football player, futsal player, sport performance, mental health, significant difference, physical activity, covid pandemic, team sport\n",
      "Cluster 6: music student, music performance, acoustic environment, music listen, musical instrument, musical experience, frequency band, performance anxiety, old adult, music therapy\n",
      "Cluster 7: body image, food choice, attentional bias, eat disorder, eat behavior, food craving, body dissatisfaction, unhealthy food, food rejection, ab food\n",
      "Cluster 8: cognitive diagnostic, sample size, latent class, cognitive diagnosis, item response, classification accuracy, parameter estimate, cognitive diagnosis model, diagnosis model, item parameter\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df3['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df3['Cluster9'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=10)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df3['Cluster9'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9be0e-e7b9-4e10-b486-2a131587c36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881a0be-8315-4fd6-985b-5ab55f4766fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c7d02b2-97ba-4f68-970d-6429a478ecd3",
   "metadata": {},
   "source": [
    "## GROUP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193aef34-4cfa-485f-a78a-6c9f006be948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster4\n",
      "0    3407\n",
      "2    3265\n",
      "3    3042\n",
      "1    2461\n",
      "Name: count, dtype: int64\n",
      "Cluster5\n",
      "0    3265\n",
      "3    3042\n",
      "1    2461\n",
      "2    2057\n",
      "4    1350\n",
      "Name: count, dtype: int64\n",
      "Cluster9\n",
      "0    3042\n",
      "2    2193\n",
      "5    1972\n",
      "4    1350\n",
      "1    1036\n",
      "3    1021\n",
      "8     647\n",
      "7     646\n",
      "6     268\n",
      "Name: count, dtype: int64\n",
      "Cluster10\n",
      "3    2266\n",
      "2    2193\n",
      "5    1972\n",
      "9    1350\n",
      "0    1036\n",
      "1    1021\n",
      "4     776\n",
      "8     647\n",
      "7     646\n",
      "6     268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df4 = df4a\n",
    "print(df4['Cluster4'].value_counts())\n",
    "print(df4['Cluster5'].value_counts())\n",
    "print(df4['Cluster9'].value_counts())\n",
    "print(df4['Cluster10'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb9d3e5-6d1d-458e-8656-c7f933dbb1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: structural equation, college student, datum collect, entrepreneurial intention, equation modeling, mediate relationship, job satisfaction, structural equation modeling, purchase intention, practical implication\n",
      "Cluster 1: mental health, college student, physical activity, social support, covid pandemic, sleep quality, quality life, depressive symptom, anxiety depression, university student\n",
      "Cluster 2: old adult, facial expression, emotion recognition, significant difference, second language, work memory, young adult, executive function, control group, individual difference\n",
      "Cluster 3: covid vaccine, covid vaccination, vaccination intention, vaccine uptake, covid vaccination intention, vaccine hesitancy, information need, covid vaccine uptake, fear covid, vaccine information\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster4'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=5)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster4'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2358a7a3-69c7-4d9d-8d26-5928037592c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, college student, covid pandemic, structural equation, social support, datum collect, physical activity, social medium, mediate relationship, mediating role\n",
      "Cluster 1: old adult, facial expression, work memory, emotion recognition, executive function, significant difference, young adult, second language, control group, cognitive function\n",
      "Cluster 2: video game, school bullying, cyberbullye perpetration, moral disengagement, cyberbullye victimization, school student, bully victimization, social medium, prosocial behavior, mental health\n",
      "Cluster 3: academic procrastination, video addiction, short video addiction, physical activity, short video, work procrastination, time management, college student, procrastination behavior, procrastination scale\n",
      "Cluster 4: covid vaccine, covid vaccination, vaccination intention, vaccine uptake, covid vaccination intention, vaccine hesitancy, information need, covid vaccine uptake, fear covid, vaccine information\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster5'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=6)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster5'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40741099-1599-4b73-90a7-b1cc3e78e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, social support, physical activity, college student, covid pandemic, depressive symptom, quality life, social medium, sleep quality, anxiety depression\n",
      "Cluster 1: structural equation, work engagement, college student, job satisfaction, datum collect, covid pandemic, emotional intelligence, foreign language, mediate relationship, equation modeling\n",
      "Cluster 2: old adult, facial expression, emotion recognition, work memory, significant difference, second language, executive function, sign language, young adult, control group\n",
      "Cluster 3: entrepreneurial intention, purchase intention, structural equation, social medium, college student, entrepreneurship education, equation modeling, significant positive, structural equation modeling, datum collect\n",
      "Cluster 4: music education, music performance, music listen, music training, music therapy, music teacher, performance anxiety, flow state, public performance, musical instrument\n",
      "Cluster 5: academic procrastination, video addiction, work procrastination, short video addiction, physical activity, short video, maladaptive perfectionism, college student, time management, procrastination scale\n",
      "Cluster 6: visual metaphor, conceptual metaphor, conceptualization time, sport fanaticism, defeasible reasoning, verbal metaphor, multimodal metaphor, scientific metaphor, word pair, visual field\n",
      "Cluster 7: fit index, type error, sample size, type error rate, error rate, pglogit model, free model, rate false, residual variance, model evaluation\n",
      "Cluster 8: psychedelic experience, mindfulness meditation, mindfulness meditation psychedelic, attribution consciousness, meditation psychedelic, challenging experience, psychedelic drug, psychedelic integration, mystical experience, category comprise\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster9'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=10)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster9'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5bc9625-eca9-4246-9258-46c1526fe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: mental health, college student, covid pandemic, social support, physical activity, depressive symptom, structural equation, university student, mediate relationship, quality life\n",
      "Cluster 1: old adult, facial expression, emotion recognition, second language, work memory, significant difference, young adult, executive function, child language, heritage language\n",
      "Cluster 2: purchase intention, structural equation, green innovation, consumer purchase, perceive value, social medium, equation modeling, consumer purchase intention, structural equation modeling, short video\n",
      "Cluster 3: entrepreneurial intention, entrepreneurship education, college student, student entrepreneurial, entrepreneurial performance, entrepreneurial behavior, entrepreneurial selfefficacy, entrepreneurial orientation, psychological capital, innovation entrepreneurship\n",
      "Cluster 4: social medium, gender stereotype, fake news, sexual orientation, sexual minority, prosocial behavior, social norm, autonomous vehicle, lesbian gay, body image\n",
      "Cluster 5: athlete burnout, soccer player, athlete engagement, coachathlete relationship, state anxiety, sport performance, motor skill, team sport, motor imagery, elite athlete\n",
      "Cluster 6: music education, music training, music listen, music teacher, music performance, music therapy, performance anxiety, musical instrument, mental health, music performance anxiety\n",
      "Cluster 7: covid vaccination, covid vaccine, vaccination intention, covid pandemic, vaccine uptake, fear covid, vaccine hesitancy, covid vaccination intention, adoption behavior intention, charitable cause\n",
      "Cluster 8: academic procrastination, video addiction, work procrastination, short video addiction, short video, physical activity, maladaptive perfectionism, time management, college student, procrastination scale\n",
      "Cluster 9: psychedelic experience, mindfulness meditation, mindfulness meditation psychedelic, meditation psychedelic, attribution consciousness, cognitive liberty, psychedelic humanity, archetype symbol, challenging experience, psychedelic substance\n"
     ]
    }
   ],
   "source": [
    "###########  BEST so far\n",
    "\n",
    "np.random.seed(40)\n",
    "random.seed(40)\n",
    "torch.manual_seed(40) \n",
    "\n",
    "abstracts = df4['Abstract_join'].dropna().tolist()\n",
    "cluster_labels = df4['Cluster10'].astype(int).tolist()  \n",
    "\n",
    "# Apply BERTopic with Predefined Cluster Labels\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 4), stop_words='english')\n",
    "bertopic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ClassTfidfTransformer())\n",
    "\n",
    "# Fit BERTopic using predefined cluster labels\n",
    "topics, _ = bertopic_model.fit_transform(abstracts, y=cluster_labels)  \n",
    "bertopic_model.reduce_topics(abstracts, nr_topics=11)  \n",
    "\n",
    "# Store topics in dataframe\n",
    "#df['topic'] = topics\n",
    "\n",
    "# Get Top Words per Cluster\n",
    "topic_summary = bertopic_model.get_topics()\n",
    "\n",
    "# Print Cluster Topics\n",
    "for cluster in sorted(df4['Cluster10'].unique()):\n",
    "    if cluster in topic_summary:  # Ensure the cluster exists in the BERTopic output\n",
    "        print(f\"Cluster {cluster}: {', '.join([word[0] for word in topic_summary[cluster][:10]])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
